{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we'll see how convolutional neural networks work and how to model them using TensorFlow.\n",
    "For this task, we'll use the MNIST dataset for handwritten digit recognition.\n",
    "The final model is the same one from https://www.tensorflow.org/get_started/mnist/beginners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import TensorFlow and MNIST\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# load data and targets as one-hot vectors\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape (784,)\n",
      "Total of images for training 55000\n",
      "Total of images for testing 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFNCAYAAABc5iZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAAIABJREFUeJzsvVdzW1eW/v0ARM45AwwASMqy3WV3T1VXX/W3npup6u6r\n+U9PjW1JthhBBCLnnMN74XctH1BZOhJJYf2qTslBJKVzsPd59grP0vzjH//YQBAEQRAEQQW09/0H\nEARBEATh60GEhSAIgiAIqiHCQhAEQRAE1RBhIQiCIAiCaoiwEARBEARBNURYCIIgCIKgGiIsBEEQ\nBEFQDREWgiAIgiCohggLQRAEQRBUQ4SFIAiCIAiqIcJCEARBEATVEGEhCIIgCIJq6O7rB//973+/\nrx/9VfPPf/7zk75ensvnQ57Nw0Sey8NFns3D5W3PRiIWgiAIgiCohggLQRAEQRBUQ4SFIAiCIAiq\nIcJCEARBEATVEGEhCIIgCIJqiLAQBEEQBEE1RFgIgiAIgqAaIiwEQRAEQVANERaCIAiCIKjGvTlv\nPgY2m83WvzebTTSbTbRaLazXa/7vWq0WWq0We3t7MBgMMJlMr1x6vR4ajQZarRYajeZL/1V2ks1m\ng/V6jdVqheVyiV6vh263i263i/V6zf9fidFohNlshslkgtVq5Uuv19/T30IQPp7NZsPXaDRCq9VC\nq9XCfD6HyWSC2WyG2WyGxWKB1WqFyWR65etprdA+J3uY8C5EWLwHJDBKpRKeP3+O58+fY7FY8P/X\n6/UwGAzQ6/VwuVzweDzweDzwer3wer3w+Xwwm83Q6XTQaDSyKL8Qm80Gy+USi8UC4/EYNzc3uLq6\nwtXVFYuN1Wq1JSBdLhd8Ph98Ph9CoRCi0Sj0er0IC+FRohTX7XYbv/32G3799Vf0ej34fD54vV4E\nAgGEQiGEQiHodL+/EmiPojWyXC55j9NqJdAtvB0RFu/JZrNBqVTCv//9b/znf/4nZrMZ/z+l8g+F\nQojFYojFYtjf38dqtdoSFXt7e/f4t9gtSFjMZjMMh0Nks1n8z//8D/77v/8b8/kc8/kci8ViS1hE\nIhHs7+9jf38fx8fH0Ov18Pl8sFqt9/g3EYSPY7PZYLVasbD49ddf8V//9V+oVqv8OT86OsJyuYTF\nYoHT6dw6/CwWi611otVqRWQL70SExTtQhhLn8zmGwyE6nQ5GoxEvWKPRyCmP6XSK6XSK0WiE8XjM\nv/p8PjidTjgcDlgsFuh0Ouj1ehEaKkMiYbPZYLFYoNVqoVaroVwu4/z8HJlMBoVCAYvFgi8lGo2G\nN9jhcIjZbPZKumRXUYbFlfdEeSperVa8BqbTKZbLJV9vSj+9Cb1ez+vKaDTyZTAYsLe3h729PTk9\nvwckFJSp2OVyiU6nAwCYz+f8bGhfW6/XHO2jKxgM8rW3t7f1fXcd5b4DYOu+kTCjf57P57yv0Lvl\nTZCQ0+l0MBqNsNvtsNlssFqtfN8f4v0XYfEB6HQ6WCwWOBwOAODNkxbhfD7n/P1wOESv10Oz2USl\nUkEkEkEkEkE0GoXH4+EPhwgL9aHFOpvNUCqV8PLlS7x8+RI3NzeoVquYz+e8ed5FuUgf4oK9T+j0\nezeFRPeaLqpFajabGI/HmEwmGI/HWCwWLDJet5nevd82m43D9V6vF263Gx6PB3a7ncW8CIu3Q2IC\nAKxWK0KhENLpNPb29jCdTtFqtTAcDvnQdHt7i+l0islkwsKQBOPTp0/x9OlTOJ1OGI1GFnfC79C+\ns16vMR6PMRgMMBwOMRgM0O/3MRgM0Ov1+CJxQfvQ69aEXq+HzWaDzWaD2+3mKJPZbH7Qwk6ExQeg\n1+thNpvhcDj4BEYfDgoVLpdLDIdD1Ot11Ot1lMtleL1e7O/vYzgcAvjjBHG3UEpQB1rcs9kM5XIZ\nz549w//7f/+PCzfn8/lbTwoiLt7MarXikxfwx72myNxwOEQ+n0c2m0U+n+d73uv1MJ1O+bSmFCVv\nusc+nw/7+/s4ODhAIpFALBbb+v1S+/JuKP2q1Wphs9kQCoWQSqWwXq+RzWZRLpcxGAwwGAzQarXg\ncrnQ7/f5RUgvPtrbXC4XUqkURyxEWPwBrQUSFp1OB81mE41GA41GA/V6HdVqla/xeMyi7U1RPKPR\nyOI6Go1iPp/D4XAgEokAeLj7kwiLOyg/HKvVCqPRiDfNcrmMXq+H5XKJvb09PjGZzWZWlVqtll9a\nWq0WOp0Oo9EI9XodJpMJm80Gk8kEiUSCUyHUUSKnr0+HBMV0OkWn00GtVkOpVEKhUOATtXIR312Y\nd0PGD3Xhfk7urgFlaoNOYePxeCu1QZGJ0WiEQqGA29tbFAoFPvlOJpOt8PD7iDrqslqtVnwC7PV6\nCIVC8Pv98Pv9cDgcXFRIhYfCHyjD5SaTCT6fDwcHB5hOp2g2m5wS0Wg0mM/naDabLCpGoxF0Oh32\n9vag1+s5NUgvQtrndmmNKD+36/V6K7qjvFqtFtrtNlqtFgu1fr+PXq/H60eZDqF3AAk25cGn3+/z\nz4hEIhgMBlitVtjb23trGuU+kZX4GiitQaH0crmMUqmE3377DYVCAb1ej3PxLpcL4XAY8XgcsVgM\nBoOBN2VKh1B6pFqtotvtotVqYbFYwGw2Q6/Xc+5YhMWns1qt+L5XKhVe2BTWfZ/8/t1FvksbJ7Dd\nTTOZTNBoNLbSG41GA51OZ0uAUO54Pp+j3W6j0+mg3W7DYDDAaDTCZrPxhvmh1Ot1DAYDNBoN5PN5\nhEIhHBwc4PDwEOFwGA6HAw6HQ4TFOzAYDHC73VgulxiNRsjlcjAajSzcNBoNRqMRvxwXiwWMRiOs\nVivsdjunoJRrYtfWBkFrpN1uo1ar8Zqgazgc8rW3t8c1dU6nEzqdDg6HA5vNhg+U1OZOhf6UghqP\nxxztaDQaHPlbrVYPem+SlXgH+sBQASYJit9++w3FYhG3t7fodrtwOp2wWCzwer04OTnBd999h2+/\n/RZms5lPepVKBdfX18hkMqjVaqhWq+j1emg0GjCbzQgGg3A6nQAgIV2VoCgT1ba0Wi0MBgOuhXnX\ni42iFbTgd1HsKWuGBoMBKpUKstkscrkcr4Farcai4u6l7LgJBAKw2+3w+/0wGo3Q6XTcIfUu+v0+\n6vU6arUa5vM5C/BwOIzBYMAnvc1mA5PJBIvF8gXuzuOFhIXRaMR4PIbH44HRaOSI03w+h1ar3QrN\n7+3twWazwev1wuFwsLDYZSiaQMIil8shk8mgUqmgVCqhUqlsFWz6fD4ueqUCfgBbh0qr1Qqn0wmn\n0wmDwcBf32g08PPPP6NWq6HZbKLX62EymWC1Wj3o/WlnhYUyx0vhcwqhU3FNp9PB2dkZzs/PcXFx\ngclkAgD8QQmHwwiHw3jy5AlOT09xenoKk8nEwsJms3H9xWKxQL/fR7vdxmq1QjAYhM/ng0ajQSgU\n4nDjrp8EPhVlfpMU/ng8xnK5fOPX0MtOr9fD7Xbz8/V6vbBYLF9tHvluWJc+p9PplIvOms0mrq+v\ncX19zTn5crmMZrPJIoxOXNS9YTab+b/TGgmHwzAajez58j6f73a7zd+r1WphNBqh0+lgMplsne72\n9vbgcrk+5616tCifsbJ7527RIBXVKqGInU6nY5M/EtwP+bT8OaFuMxLdzWYT1WoVxWKRo6Oz2Qwa\njYbNEt1uN/x+PyKRCEepdTodR/PIjI+EhV6v54i51WpFLpeDRqPBeDzmOqXlcskHoIfIzgoLAFsn\nLArxNptNLrys1+solUooFotoNBpwOp2Ix+Oc/ohEIgiHw4jFYgiHwzCZTJwK2Ww2cLlciMVivBDH\n4zEqlQpGoxHy+Tw0Gg16vR6+/fZbWCwWDhc/VBX6GKCagH6/zyHJuy2ldzGZTBzqTSQSSCaTOD09\nRTweh9frhcFg+EJ/+vuBWqmper3T6aDVaqHZbKJWqyGfzyOfz6NUKnEHAW2a5NpINQ8+nw8Gg4Ev\nl8sFl8vFGyaFhd+H4XCIRCKBZrOJQqGATCaD6+trjEYjVKtVPj1brVaEw+HPfJceL3TCnkwmaLVa\nqNfryOfzaLVamE6nb/06EiKLxQLr9XpLTO6isFDW+9AaabfbGAwGMJvN7AuidF2mbiaPx7PVKk2H\nSWolJbG8t7fHEbper8cdOPQ8KE1JNXwPkYf5p/pC0KKhFrlsNotsNovb21vc3t6iVCpttQx5vV7E\nYjGcnp4iFoshGo0iEonAbrfDYrHw6QoACwutVstdJNVqFSaTCfV6HblcjvNyZrMZiUQC4XCYQ7u7\nuGjVgAqq6AU5Go3eKSyMRiNcLhcCgQD29/eRTCbx5MkTdkz9mtNU9NJZLBbo9XqcsiuVSlxfRFer\n1eKv0+v1sNvtcDqd8Hg8SCaTSCaTODw8ZHtoi8XCpzKDwfDBLySKnAyHQ1xcXGC1WnEqktqGN5sN\nQqEQTk9PP9ctetQoWyCpqLBQKLCwUBr9venrqcWYIhy7HLGgiCjVVjSbTXQ6HQwGg63oHNX9OJ1O\nFt8kGui+0X2kdUHRN2VUxG63w2QysYCgZzGfz6HT6R6sx85OCQtl+mO5XHKbVafTQSaTweXlJa6v\nr3lTrVQqHCKnKMXh4SG++eYbRCIRBINBBAKBN6YwKIxutVrR6/UQj8cRj8exWCy4fgMADg8PUSqV\n4PF4YLFYYLFYYDQav/wNeqQo54EMh0N0u100Gg3UajXuF7+LsvPD6XQiEong8PAQyWQS+/v7vDl8\nzRsoierZbIZ2u82dHOVymaN37XYb8/mcC89IKJjNZj6J+Xw+JJNJpNNpHB0d8XwVi8Wy1WWj5E33\nVFkNP5lMeEOu1Wrcu0/Pmgrc3qd2ZpdQ3ov5fM4+IlQrQ2mtRqPB6V3lelDeT0qNUVGnsqNnF++5\nsrCZogZUaxcOh3FwcICDgwOO0t2N1L3tc0/QM5tMJhgOh5z2UJrDPfSU+U4JC+CP9MdkMkGxWEQu\nl0M+n+coRbFYRL/fx2g0gkajgd/vZx/9k5MTnJycIB6Pw+12v9PgSml/6/V6kU6nMZ/P4Xa7kc1m\ncXNzg9FoxK6QWq2WjbREWLw/VLA5Ho/ZZZOeZbvdfm24l8KQer0ewWAQqVQKf/rTn3BwcIBAIMB1\nAA914aoBtRw2m02USiXc3Nzg5uYGrVaLXzT0+aeNUTlkj9JHDocDgUAAwWCQC/xopsTr7t/b7qmy\n02Q0GqFWq/ELsdlsYjabwWg0IhAI4PDwEKenpwiHw1K4eQcSaIPBgCNOhUKBo7LFYhH1eh3T6RQa\njYbXglarZSMzEp7kZ0GFg/T/djFlq9VqYTAYYDab4XQ6odVq4XK5MB6Pt9KBJIiVdSnvgsTFdDrl\nfezm5obrmVwuFxwOB2w2G0cDpcbiAaDMGZKwePbsGV68eMEmJlRcSflEn8+H09NTPH36lCMOsViM\n6yneFtqlwietVsvCwmazwW63Y7lccs66XC7j7OyM/4w0yEx4PyjvSeHJcrnM3Qvkr3AXymuaTCYE\ng0Gk02n8+OOPCAQCsNls711g+JhRpgCvr69xeXmJi4sLDAYDFtM+n483S7fbvWWvTTlh5awc8nZ5\nW6vu21J9yjzycDhErVZDJpN5rbBIp9M4OTlBOByG2Wz+3Lfr0aBMfwwGAxQKBbx8+ZLt7G9vb9Fq\ntdgbgfYp6tqhqAXN2VHWLZGDqtJH4WtfJ0pIhJnNZq4fIhFOKQ+KVFNq430FGD03EhaXl5e4urpi\nYeF2u7eEhRRv3iPKEBN5HNCGdXNzg7OzM/z6669shDWZTGC1WlkAHB4e4uTkBN9///2WvfD7fFjo\n9+zt7cFutwP43aZ4Npshk8lAr9dv5T3NZjP8fj8mk8nWn3uXFu77onQEpPZSOnXf3t5yqymFze9i\nNBo5BxqJRBCPx3F0dAS73b4zxWnkOZHP53Fzc8MFmsvlEoFAAA6HgwfqxWIxBAIBDsdSVEIN90vl\nPB4Ku49GI44oZjIZlMtl7gahP9fR0REODw/h9/t3Xlgo94vFYsEprmq1ilwuh7Ozs622dzK/0ul0\nsNls3AZpMpm4iJcKn6lDodvtot1uo9FoYLVawW63Q6/X79ReRcKCxAOJahLUH7t3kJBbrVYYDAao\n1WrsXkv3mtq27XY7F5Q/1Pv91QsLYLsqulgssuXwy5cvuUATAMxmM+x2O3d8RKNRJJNJpFIp7sf/\nWBtuOhVQtTyd6KjVlRYzhRppsT7UD859o2wRbjQauLm5wcXFBa6urpDNZtHtdtku93W5YIfDgWg0\nylEoj8fD0aVduefz+Ry9Xg/VahX1eh2LxQI2m42r24+Pj5FOp+HxeOD1emG32/ll9KGnsbehHGBG\ntR50FQoFFAoFrrpPJpMcrUgkErwuv+YC2/dFmf6gLrerqytkMhnc3t6iXq+j3+9juVxyzYzD4WC7\n6EgkAqfTiVqthlqthnq9zu6RZM2ey+Xw7Nkz7O/vIxaLcbh/V9YMtZFuNpstYf2phxGKoo/HY+7c\nqVQq6HQ6CAQCCAQCiEaj2N/fZ++jh3zPd0ZYKOsqnj17xoZXJCwoSuF0OpFKpdibgh4qFWl+7CKi\nql868SlDjkrfAKWweMgfnPuGwrPD4RCNRgPZbBbPnz/H+fk5b4J0H+8KC41Gw8Li9PQUiUQCbreb\nn+2u3HfqBKlUKmg0Gliv17DZbPD7/djf30c6ncbx8THni00m0yvthmrcK+o8oGm019fXeP78OQqF\nAteA6PV6bu8+ODhAKpVCPB7nephdFxbK2pTBYMDRu8vLSxYWjUaDjZdMJhOcTifC4TASiQSOj49x\nfHyMQCCAXC7HtWe5XA7z+RydTge9Xg/5fJ7dOk0mE0KhEHcs7MK6obo5rVaL9Xr9ipHex64JEhY0\nuJLminQ6HSQSCW4aCIfDPNr+IfPVCwsqQJpOp2g0GigUCjg/P8evv/7K/u20SLxeLyKRCNLpNJ4+\nfYrvv/+eq9uVY2o/BhrYozztUYX7bDbDcDjkHCYZoCjNaIRtlPet3W5zodP19fXWmG4lSldNSoGk\nUik+qVHEYpegjZDCu2azGdFoFAcHB3wq/RwjypWzJsgXYDAYIJfL4eLiAs+fP2fHTXIv9Pl8SKVS\nSKVS2N/fZyfDXV0fdzsJ7qY/zs/Pua6iXq9jOBzy4cblcrE1ejqdxjfffINvvvkGoVCI2+f1ej1m\nsxkX81Ih6GazgcPhQDgcxmKxeGet2dcERZ7V8I9QRur6/T53st3e3qLZbGI4HGK9XsNutyMej+P4\n+Jg7rh76vf7qhcV8Pmf1p7Re7fV6WK/XnLPd39/H4eEhtxyGQiEu4vucJiQUsdBoNJzXpAE1yjCb\nsA31eiuHAJEge1P6Q+l05/V6uePB4/FwK+MuYbfbcXR0hOl0iuPjYz75ezweHBwcwOl0frbheBSh\nWCwWKJVK3K1AnSnVahXr9Rp+vx9ut5trKpLJJKLRKNtR79ozuwuJM/L2qFaryGazuLq6wtXVFSqV\nCk/0NRqNcLvdcLvdCIfDSKVSXKcSjUY5peRwOBAMBjGbzVCv12Gz2aDT6bBYLDhCSOZzVExLEdhd\nfx4fAh2MhsMhKpUKf/bL5TLa7TbXVITDYXg8HthsNr7XD52H/yf8RGazGVfYXlxcsLDo9/tcwety\nuZBIJDj9Qb7u1E76OStv6eS9Wq148h31jAN4sFW/9w1ZUJOwmM1mLCwoLKyEcqM0UMnr9SIQCCAU\nCsHlcu2ksLDZbEgmk3A6nZhMJlv23FSB/rnMkOhzP5lMUCqV8OzZM/z73/9GqVTiMeterxc+nw9P\nnjzB0dERd2R5vV7uTtlllOmPTqeDbDaL8/NzLvrL5XLodrs8WZZeVBRaT6fTSKfTiMfjW4PcHA4H\nVqsVACCfz3NtDXn/LBYLNp+bzWZYLpcckRXen/l8jm63i3q9jpubG7x48QK//vorWq0WHA4H7HY7\np/9IWHyIc+198vD/hO/J3bkH1A3Q7XZRKpVweXmJs7Mz9jaYzWZwOp1wu91sjpROp3F6esodIV+i\nN55O3mSaRdGKh+6sdt8sl0uMx2OuVKdBY7Qh3kWj0XAnCL2w6KKw765FhiwWC0wmE8Lh8CtjsKkm\nSM17Qi9CKqSmmTz5fB4vX77E//7v/6LdbnOq0Gq1IhKJ4MmTJ0in0/D7/dwOLGxHfZrNJnK5HF68\neIFCoYBKpcLDsGj8PO11yWQSx8fHSKVSHJ1VHqDoBUZt8larFXq9ntu6J5MJe/3MZjMsFosHPcL7\nPrg7o0XZAkzpj06ng0qlgmKxiEwmw5b10+mUa52Ojo4QDofhdrsflVfLVyMsgFc98VutFm5vbznX\nqOwAoZY16vqgB3jXQlV4mNBJ98WLFzg7O8Pt7S1Go9Ebf79Go4HNZkMgEEA8Huf8PIUWd01UEErH\nRWWh6+e4H/QSnM/nPLipVCrh4uIC9Xody+USLpeLHW2piJqiFBSSF35nPB5viTMaQ9BoNDAcDrFa\nrWA2m3lORTwex8nJCdLpNBvBUVRWWSNB5nFKjxKTycS1S2QpTRelH4XXo7xfg8GAn1m1WmUjP7LL\nPzo64u6no6MjHBwcIBwOw2q13vPf4sP4qlapUlhUKhVWgVQZXalU+ERGwuLp06f49ttv+TRkt9sf\nTbhplxmPxygWi3jx4gVevnzJodk3odVqYbPZEAwGcXh4yNXVVEOzy8KCfr3rR6B2+mO5XG7ZS19d\nXeH8/By5XI6Fhd/vRzKZxNOnT5FMJpFIJNjp9rHkl78Uo9EIjUYDlUoF+XwehUIBxWIRnU6H06sW\ni4U7aegQlUql+BBFwkL5vCnCoTQ+M5vN3LGmFBVUXGs0GiVi8RooIj2ZTNhJlgZbKi8ACAQCODo6\n4gg6iQqbzSbC4r5Qpj/6/T7K5TKnP0jNd7vdLQviRCKBk5MTPH36lLs/7iPcpBxKo8xp71rO/3W8\nbuwztdTRM6YBVW9LGykjFgcHBxyxeMi2uJ+bzzFv4O7LRRkCphA6pSczmQznlMfjMbugplIp/PDD\nDzg8PITX693Z4tq73J3RMRwOUa/Xkc1mUSgUUCqVUK1WMZ1O+XDkcrkQjUY5UkEF6mTyd7c4d7PZ\nsNAgh1WycKc5ITQr4+68ll3jdZ91SvXRPkWGVxSlUE7ppQhTuVyG0+nkuq9UKsUzR/x+/6N8F3w1\nwoLMfrrdLgqFAlfYFotFdLtdLBYLWCwWJBIJri5/8uQJh5loNO2Xhvqi9Xo9K1Oz2bzzIfq7UCSK\n2hILhQLbElMXyNtOTBqNBhaLBT6fj0PrNCRLUB+lkyZ17VSrVc7907yKwWAAi8WCSCQCl8vF8z+i\n0Sjnld82vGnXUKYjGo0GcrkcXr58iXw+j06ng9VqBZvNxt0fh4eHePLkCY6Pj5FIJHhir9J74S53\nJ27q9XoYjUYWLMAf6RIabaAcjLVLkIAgw77pdMqGh+RN1Ol02GisXq+zAVmz2US/3+cidHJgpiiq\n2Wzm9mDyP3osfFXCot1u80kok8mwvTNVLtvtdiQSCfz444/47rvvEAwGEQqFtrzdvzTKoTYUmiRh\nsYsFha9D+ZJqNpuoVqtbwuJ9pltqtVpYrVZ4vV7E4/EvVpy7iyhPblRg2+12t9pJa7UaWq0WBoMB\nYrEYeykkEgnuyiLr4l2NKL0O5URapbCo1WosLKjo9fDwEKlUCicnJzg+PkYwGOSC3bd1+ygjqMrB\nc+PxmPcjOhCRsNjVFNXdycrkjUTOpfQrXYPBYGt8xGQyYQ8SMoKjuSMOhwMWi4XHDIiw+EIoQ4NK\nxUdDi3K5HGq1GttoO51O7O/v409/+hP+8pe/bA1Uui/oA0MmXFQoRRvqrgsLZSh9PB6j2Wwin88j\nn8+j2WxiOp1uhWHvbpS0eVKXAZmg0UlsF09ZanNX1FHVO6Ulm80mzz64uLjA+fk5RqMR5+fJ7fZv\nf/sbIpEIh9539WWl5G4qkEZqUxqkUCjg4uKCx2uTe2okEuFpzMlkEslkEi6Xi7/Xuz73SjM5WivK\n/eiuk/AuRiwoLUSRCmVkgqzoC4UC+4vUajUsFotXvg911AyHQ1SrVU5hUYsp2YeTb8tjMCN71CtX\nWUhUq9V42M7l5SXnGslJkOZ+nJ6ewu/3P5hUg7K1T6/Xb81geOgfni8BLd7lcoler4discjPuFar\nvXYkOqHVarluhuZdWK3WnRkydh+Qp0Kj0UCr1eLUR7VaxWAwwGazQSwW45Ow0WjkF5+yS0eezTa0\nDigqWy6Xkclk0Gg0MJvNuDZCq9XC4XBwyo9G2X+I5TmJ+eVyyUPhlHOMhN9ZLpcol8tcKzEej7kd\ndzQaYbPZwOfzwWazIZFI8HOiPV8J2dqv12sYDAaMx2NcXV2h2+0iEokgEokgGAyyFcJDL+Z81MKC\n+qpJ6ZGwuL6+5oVgtVqRSCTwww8/4OnTp9jf30cgENga73zfKE8FJCzoz7XrGyxN/aMamtvbW57U\n2Ov13iksbDYbvF4vwuEwfD7fa9vrBHWgF1K73WZ79VKpxJfT6YTH4+EaF7rIqExZTCvP5g+U/get\nVgs3Nzc8Bp3mf2w2G7aaJiOsWCyGUCjExlcf8vMo4jSbzdhynYy2pPvjd8g19ueff8aLFy+2/Cro\nQEO1XHS9aWDZeDzmaAd5hDSbTWSzWRweHvK4B/IcEWGhMqT4SFFTDpciFuQ8R5DT3I8//ogff/yR\nu0IeimsfqVcq4FRzauTXgFJYUDcBtSi+DuXwNlqAtMlSxELu76ejXIf07/RCopffTz/9tNVSd3p6\nysLi6OgIiUQCiUQCVquVX4ryXF6FhAUNactms3j27Bmq1SqazSbb/9MYb4fDAb/fj2g0imAwyPVa\n7yvWqBiRhAVFLCh1JfzOcrlEtVrF8+fP8a9//YtT6yaTCfF4HFarFT6fjyfHUprvdXs8PddsNotM\nJoN2u43r62tOe81mM6zXa2i1WnYOVj7PhybEH52wAMA59X6/j3w+j6urK7x8+RK3t7cYj8cwGAws\nIA4ODni2wH12f9yFNmQaXxwKhRAOh+FyuR5Vkc7nhsQjFUUpaypeN7VU+c/Kdjvl/JfPZVO9ayjF\nhDK/fH6ZIHPUAAAgAElEQVR+jtvbW3Q6HTb7OTw8xNHREdtIB4NB9qaQCNKbodbqwWCAbreL29tb\nlMtlVKtVdLtdTKdTbDYbFtA0mVbpKPshEaC7DpHUWkpGWLvYVvomdDodotEofvzxRxZvVM+ndPYl\ngzKLxcID25QRaeXz22w2PHk2GAyi0+lAr9ej1+vh7OyMI/Ttdhsulwtutxsul+sVD5r75lEKC/rw\n0zTEn376Cefn5yiXyywsfD4fTyqNRqNb1rQPQVgQNPQnFAohGo3C5XI9mGjKQ2CxWHBUitJbSpc/\nWlC0QJUeIHq9/hVhQRXW9DXCx0MvIGp9VLZ4k1FTKBRi0RyLxRCNRhGLxbgrRykshFdZr9dcqKnM\n59dqNW7jpRdTKBRit0a/37/1IvsQlD4MJCzoxCxpkD/Q6/WIRqPQaDSIRqMcddPpdFyMTwX5dN01\nIyOsVivPp/J4PAgGgzg4OOBpp8ViEYVCgQVms9nE4eEhAMDpdAJ4WPvZoxMWSkWtFBaXl5fchkVm\nIwcHB0ilUojFYhyxeF3hzJf+sysXJw39oc3X7XZLxELBcrnEaDRiYUHzQF5nTqM0fKKCWBqPfnR0\nBLfbDbvd/qAW4GNGWeTXbDZxdXWFX375haMXnU6HWx7//Oc/w+/38+lN6ijeD9rnKNVbLBY5YqFc\nAzabDaFQiEfK+/1+Pkh9KMpIFM0jmc/nav61vgpIWASDQaxWq63aCeWvwLtf+nq9HhaLBX6/n6fI\njkYjjsL/9ttvODs7Y1HRbDYBgKMVyoPVQ+DRCQsyHxkMBltz6yn3p9frYbfbeZFR2NVisdzrqWg0\nGnFf89nZGSqVCiaTCRdbBQIBruDedWExnU7ZWIlGat/c3ODq6gq1Wg2z2ey1FtTA76PRPR4P3G43\notEoUqkUmy3ZbDZpMf0ElPd7uVyygGg2m8hkMqhWqxgOh1wwazKZeA6P3++Hw+HgommJULwZ5X1e\nrVZs3U373Xg83orUaTQazucnEgku2PwY8UYW1BRyf1MnCKVKqO6ChPyuQfVxykjEXefk930Gytow\nilp7PB4u3rRarSz2isUi7HY7jEYj1us1p0RcLtfW2rqvve7RfRLIr4IGuDSbTYxGIyyXS37Id4WF\n0+m8d5dFUp/n5+c4OztDqVTCZDJhAxS/3y/C4v+HesI7nQ5ubm5wdnbGNTT1eh2z2Yx/7926CoPB\nwJ77qVQKx8fH7OpI+U/h46EXGqU/qOCsXC6jVqthNBohEAiwdXQgEIDf72ehYTAYRNh9AGQJXa/X\nt4QF8McIADJ/o0L1j+kEIcgrg+qaqBPkdb+PiqqXy+VHRUa+BpRiQPnvn/IZJ28jrVYLj8eDZDLJ\n+1oul0M2m0WpVILBYMB6vcZoNOLZIg6H40HUjz1aYUHzP2jOwHK55AIau92OcDjMwuJuYdh93HTl\n0Kzz83NUKhVMp1M4HI4tYUEFV7vMbDZDt9tFuVxGNpvF2dkZfv75ZzSbTfYtAV7/HA0GA4LBIE5O\nTvD9998jHo9zxOJNXyN8GHSqbTabuL6+xosXL7i4djwew+l04smTJ/jb3/7Ga5IiRXL/3x9K+VK0\nU7nfAdsmVjabjSMWXq/3o2vJlBELajF9U8SChMVisYDBYNi5+ovPMWuHvh91CJINQSAQQDQaxXK5\nxM3NDUqlEpsGttttrNdrOBwOJBKJB1FD9iiEhbKughZZLpfD7e0t2u025vM5d1d4PB7uArnvlzRV\nVZO5E0VaWq0W5vM5jEYjm51Qkc+u2ngr2xaVfhWXl5col8tvra8ghW8wGOD1euH3+xEOhxEOh3mA\n1S7eUzVQPpflcsn23FRTUSgU0Gg0YLFYEIvFYLVakU6nEQqFuI1UDMk+DKUp3HA4RK/XQ6fTYQt0\nEtZWqxVOpxMOh4ML1M1mM592P+Z+07A4esb085TzQygyLM/287y8lYKFWoiB3wvZE4kEnjx5guVy\nic1mg9lshlwuB5/Px4dTu93OxaKSCnkLSlcyEhbZbHZLWFBuPR6Ps2q/7+6K1WrF9QLdbhftdhuN\nRgPdbhcajYb94G02G28Iu9zLTwKy1+shn8/j2bNnKBQKqNfrbx02tre3B4vFwqc2qlcJBAKSWlIB\nuuez2YyLCHO5HEcNO50OvF4vp5+i0SgCgQB/lnf1pfOxUDpiOp2i3++zsGi325jNZiws7HY7IpEI\nYrEY9vf34fF4WFR87B6yXq95v6rX6+j3+5x6VPrtUCRK+YzlOasPtc1TC+r+/j6WyyVsNhsKhQLy\n+TyKxSICgQDve1QkbTQa7+1d8miEBYXeqPUql8uhUChgNBphsVjAZrOxsIjH47zI7hMaGESnjlar\nhUajgV6vx9asSmGh9ILfNZQdMyQsnj9/jnq9zhMDlW2mSvb29mA2m+F0OuH3+7eExWObCvgQofU3\nn89Rr9dxcXGB3377Dc1mE41GA6PRiP0q/va3v/FpaReL+dSAzLAoHdHtdllYKIU1CYuTkxMkEgne\n8z6lnZ6mCHe7XTQajS1hQRNNaU3J+IHPjzItsre3x4ZygUAA6/Wa34M0uC8YDPLIe0r/3gePYuUr\nJ/rRKFqyc6aTv8fjQTgc5j5uKhb70ihP09PpFO12m3vQO50OJpMJ9vb24Ha72YHQ7/fvXLj+rmMj\nncz6/T4ymQwqlQq63S7Xz9w15qFNjrwqyMUxmUxuPf9djgB9LMpns1gs+NnUajVcXV3h5uYG5XIZ\nOp2O64KSySTC4TCcTidvhIDUtHws1OZJEYrFYvGKsKZTbCAQgMvl4s63D73n5FlBHSitVgvlchn5\nfB6NRoNrOiwWC49jD4VCcLvdnL6V9uHPgzItotPpYLVaeX36fD64XC42/aP3jcvlYt+R++JRCAsa\nhkOiQtkGZTAYuCI6Ho+zyx+5+t0H9LKcTCZcaEqGQVRbEQwGkU6ncXx8zKPbgd3aiJXjtZVTS6kd\ndzqdsqi4m/4gExqbzYZwOIyTkxN88803SKfTXFuh9OUXPoy76Y98Po9cLofLy0tks1nU63Xu/CBX\nzWAwKFN5VYBSv+Qf8bq6IuD3QmVq7aUxBR9z30lAUis/tbZmMhm0Wi0Mh0MAf3hlxONxtshXmpzt\n0t51H1AkAvhdDHo8Hk79ms1mrNdr9Ho9nhx8nzwKYUG1CuRfMRqN+CRrtVq5q4IcFg8ODvg0ex8o\nhUWz2UShUECpVEK328VisYDD4UAgENiyN77PQpv74u58iUwmg19++QXZbBbVavWt0xRJvbtcLkQi\nERwfH+PHH3/EycnJ1tjtXbunanFXWFxeXuLly5ec1x0MBjg9PUUqlcJf//pX7qGXdtJP566weJOV\nNo0u8Hg87BHyMfeehAXtsSQsbm5uuEYM+F1YBINBJJNJLhYld0955p8faqenKKxSWFgsFqxWqy1h\ncZ9dOo9CWMznc/7Ak4JeLBacf6KTq81mg9VqZc+KL3VqUuY9x+MxRqMRhsMhMpkMX+VyGaPRiJ02\nvV4v2x1T+HiXFudms+EI1GAwYBOsm5sbVKtV9Pv9N9ZUAL+HgcPhMA4PD3FycsKheJfLxSdmOTV/\nHKvVCpPJBOPxGLVaDcVikV0fl8sl2+UfHR0hHo8jFArBZDLtXDrvc0FF6tRFRjNBALBoNhqNCAQC\n8Hq9bP5GNVrvg7KmaTabodVqoVaroVAocKfPcDjkcewWiwUejweRSASHh4cIh8PslSHP/MtABbLU\nBUeHqmQyyWZl5XIZfr+fu3nuq7j2UQgL8jWgaX7D4ZAtVPV6PS825cjlL3kT79qMl8tllMtlXF9f\n4/z8HNfX19xiajKZ4Ha7uS3S7XZzW94uQUWaxWIRpVKJQ+ylUolV99tyhFarFfF4HD/88AOePHmC\naDQKp9MpxWQqQO3RzWYTt7e3PKug1WohEAjg4OAAkUgEp6eniEQiW8OuhE9nuVyi3++jUqlwncNk\nMmGHTbJFj0QiCAQCvId8aOSA9qzJZIJKpYLLy0teh+12m42vaLiW1+tFOBzGwcEBtzWKqLgftFot\ntxmPx2NUKhVUKhWUy2WEQiF0u13MZjN+J37p98ujeJvNZjP0ej1Uq1VW0uS0aTAYtoTFfSloKoDq\n9/soFos4Pz/H5eUlrq+vkclkMJ1OeTCNy+XiMJbH4+GK311ivV7ztEbyq8jlciiVStwB8i5hkUgk\n8MMPP+Dp06evDPkRPh4q2KxWq8jn8ygUCigWi2g2mzg4OGDzsWAwyH4V0m6oHqvVauv+k9smCQu/\n388D3fx+P1wuF88F+ZCIBRVsTiYTVKtVXFxc4NmzZ6hUKiwsaH+lVu5IJIL9/X04HI57H5Owy2g0\nGhYWWq0Wk8mEvZ3i8Tg3N1CK/UvPEXkUwoI6ACgESLlzaoGjPKAyH/m5N7rlcsm+7dSl0uv1kMvl\ncHV1haurK7bgnUwmbMlK7WGRSIQLrnZlU1bm/CgE2+/32dvjdU5/lNKgllKr1QqbzYbT01McHh4i\nEonA6/VumfcIH44yND6fz1nIV6tV3qCCwSAikQgSiQS/XGw2285F2z43VGMxm80wnU6xWCx4TyNP\nA0r5ms1mmEym9+rMuDvrhQrhS6USp0CKxeJWx53T6eSU7f7+PkKhEFwuF3eD7MK+9RCheguLxcKp\ndIp0UXtyp9PhWrQvXVD9KHYEg8HA8+nr9TpvZuPxGOPxmHu8h8MhV1F/bke45XLJY4tvb2+RzWY5\nD00hKQrp7+3twefzIZlM4unTpzg+PuZ+5F0RFQRtbuRLQpvnm6rf9/b2YDAYYDQaeRZCPB5HOp1G\nMpmEw+HYefc/NVCOyqbUY61WQ7PZhE6nQywWg8lkwtHREU/hpReaoC60J1AI++5nWzmAjIZ/feiL\nYz6fo9VqoVKpIJvNIp/Pc6SCurH0ej38fj/S6TROTk6QTqcRCASkjfuBoLR0B8B1FjQNul6v8yH8\nS1svPAphYTQaWTlXKhVWYIvFgnPxnU4Hw+Fwy0jpc37wF4sFJpMJ+v0+8vk8fvnlF/z000+o1Wo8\nN2G9XrPfu9frRSqVwl/+8hckk0k4nU4WFrsGvcCo6l0pLO5Ck/6sVitCoRCePHmC77//HkdHRwiF\nQrDb7TuXRvpckNibTqfsW9FsNuHxeNh0TCksJEL0+aAXBl139wkSF/T7PlRYk7CgFuJcLsfCgr63\n0WiEz+dDOp3Gf/zHf2yZzknK8f55l7BoNBqcIv7SnhaPQljo9XrYbDasViuugnY4HJhMJgDAG2G9\nXkexWNxytfxQpXb3xEzpDspFUtqFQk3dbhe//fYbLi4ucH19zZXUlAOjNjxqzaPpgwaDYedCiZvN\nhqNMg8EAtVoNjUaDZxLMZrPXzgGhNBiJy8PDQyQSCdhsto9usRO2P+tUV9Hv91EqldBqtTAajbDZ\nbOBwONg2mibFKj1iXtfW9qb/poxYUY5fme66O3Ka2LVnrOwAeN29UKb+3tYBp/SKocPQdDpFrVbD\nzc0Nrq6ucH19jXK5zO3wdrsddrudbdoPDg449UVCXgTl6z/jwJf9rCrXCq0p5TqTWSFvgcyQNBoN\nvF4v9+5SGH0ymXCHwdnZGTabDeLxOOcjPwZlKxZZStdqNdTrddTrdTSbTbRaLbRaLZRKJRSLRQwG\nA2i1Wl6YNJEuGo3i4OAAR0dHcLvdOzsTZLVacYi9Uqng+vqaCzYHgwHG4/Eri5XyyiQurFYrb3D3\n6YX/tUEFfJRnr9frWK1WsNvt8Pl8LCxcLtcra4qKwwja3O6ekpTpFopWUUuc0WiEyWTaOn3vWprw\nfVCeUt+njZDEGxWE0v5VKBS4CySfz6PdbmM8HkOn08Hv92N/fx+Hh4c4PT1FPB7n1Jd4VrzK3Zf4\nly6UvPtnofel0+nkNuQvvU8+CmFBJ3saNEaT3AaDAdrtNkajEXdjmM1mvrk+n++jft7dQjbypSgU\nCri+vsb19TWLDOpSob5/t9sNp9PJ9uLHx8c4Pj5mjwUyEdrFmgASFnQfr66uWFgsFgue2KeENtG7\nwsJms8nJSSU2mw2m0yl3BhQKBU4p3hUWrzOeu/vMlB0HSpQvuel0ytErSnVRdIrC/8SurZO38Tph\n8TZoUipFpIrFIneqZTIZ3NzcoFKpsMgjf4zT01N899132N/fRywWY38YSTu+nvuOECjXIHk7kbC4\nDzH4KISFckwvhegikQgXa9JMiUajwT3XLpdra3SzsmqaXkbKzg6CNlkKGdKY6G63y6Iik8mg3W7z\nf6c6AIfDgVAotDW3IplMIpVK8YAgyk/uCnQ6XSwWGAwGXCx2fn7ORjyDwWDra5SbJ7mqhsNhdvuz\nWq33Prn2a4BqKsi3olqt4ubmBqVSiQ3nvF4vPB4PzySgiMN4POaX0WKxAPDH5kbpQjJ1IqiFWCks\nqGOKun2o84siGNT5QIeLXRDkVLhJ+wUVZ1I6g3LoNEq92WxytGdvb4/vMRWYD4dDDIdDVCoVZDKZ\nrUghmdEZDAaeuRSJRHBwcIB0Os2TMs1m833flgcHrYPxeMydU8px5Z876kbPl9LIVNNnNBphNpt5\nfLoIi7dAN8ZsNsPr9SIWi7FzY61W40JKrVYLs9nMUy739va45oImLlJ73Gw2w3g85tw+tXk1Gg2+\n2u02XxRGrNfrvJmSpS79vEgkgkgkgmg0ytPm7HY7pz++9k3xLqvVCsPhkNtKc7kcb25UW3EXnU4H\ng8EAg8HAM1WoKj0cDt/LcLmvkdVqxRtjo9FAtVpFqVRCo9HggVORSGSrnY3EBE3AbLfb6Pf7W7UT\nVH/Ubre3fp4yRUKpkMViwc/baDTCZrPB4XDA4XCwoAyHw7Db7bx2v3ZhTtFZis7RvkVutfV6nUdn\nk/Ci/c1isfC+NhqNeN9qNBqo1Wp8NZtNdDodzGYz6HQ6OJ1OuN1uhMNhJBIJhMNh+Hw+OBwOmQ78\nBuhdQanDUCjEn1dl4e3ngEZGdDodVKtVDAYDrFYr9nSyWCw8x+U+3juPRlgA4LYZGo/e7/dRq9Wg\n1+u58IwWis/ng8/ng16v55SIVqvFZrPhiMV0OkW/3+eCSzoR3NzcIJPJIJvNotls8qU8iSlVYTQa\nRSqVQjqdRiQS2RIUyhHSu5gzJmFB8wdIWFxdXXHtyl0oAmSxWBAMBpFKpfDnP/8Z8XgcHo9HhIVK\nLJdLbtdWCoter4dYLLYlLHQ6HXeMjEYjDAYDFItFbq9WCotSqYRSqYRyufzaNInSqZb8GShC5XQ6\n4ff74ff7cXh4iPl8DrPZzBGqr11UAGDjP5qDpBQWo9GI/QqsViufSL1eL1wuF5xOJwuKdruNcrmM\nXC63ZbQ1Go0wmUy20h9Op5PtuuPxOMLhMPx+P0ePhFdZLpdoNBpcuH96esodgBRh+xLColKp8AgE\nei/RdV8zkx6FsFDeFJozrzTxoRz9YrHAeDzmgkqHw4HVagW/38/jZGmhaDQa7uqgExcJC2X+sdfr\nccrDaDSyp4bT6eSaiWQyybUUwWAQHo+Hp6vuYhHa3RqVbreLUqmEm5sbFAoFVCoVNBoN/r13sVgs\nHAE6OjpCMpnE0dERt7qJIZM60IwIGjhVqVTYHAkAdy5RFwF5xQyHQ/R6Pbb7visslCdjZQfD+6wB\neukNBgOs12uOXE2nU45kKCOPX6PQoCmWFLGwWCxbUVaq+yqVSjyfhdJVLpeLhQXtgyQsBoPBVpsq\n/Qyn04n9/X0cHR3h6OgIiUQCfr+fO0C+xnusBsoavE6ng3q9zp9PKuCnSJsaaTyql6EUCPmQ5PN5\nDIdDGI1GRCIR+P1+7oikCc8iLN4BvdgBYDgcotvtYjKZwGq1cqcGFaJpNBo0m01uPaWZBqQmh8Mh\nb2TKVEiz2USj0UCn02FbW2U3Cs34oIsiFDRQjDaCXRMUBN1HCrVTCuTy8hKVSoXTH29q1/J4PEin\n03jy5AnS6TS3upGokIJNdRiPx7i9vcXPP/+My8tLVKtVbDYb7sCazWZ86p1MJlygTOKCUh79fn/r\n+y6XS1gsFsTjcRbjH3LqVaYktVotut0uwuEwpxl9Ph9v2l/jS08ZsaAXFRXMKgUcibv5fM5OnJQK\nob2N6jCoNZ+iPyQoKEK0v7+Pg4MDJBIJBINBGeb3Hmi1WrZYj0ajWK/X7AcSj8f5om6aT7UXoOF0\ntPby+TwymQwuLy+5PoYmfPv9fv559/EOepTCgtQY9WWvVisuzqQOEZoKSBsbPVil4Qypf2XxGalQ\n+u80tdFkMuHw8BCpVAqpVAo+n4+Fhc1m4/wm1VLssoGMcuzzeDxGvV5HLpfDxcUFD5F720hft9uN\ndDqNv/71r4jFYlu53l0o3vtSjEYjFAoF/PLLL7i6usJisWBhodVqOaJRLpdRKpVQq9W4JmMymXCU\nkCYN06nM4XDA6XRy947Van1vM7jhcMhhfLJ6v7m5QTAYxMnJCbtCrtdrzid/bVA0wWazwel0coSG\noLXT6/Uwn8/ZHZUuKtwkZ1tqmae5H06nEz6fj+sBotEoO9qGw2EWKLt8OHoftFotbDYbAoEAJpMJ\narUa8vk8qtUqvvvuO2w2GzidTm4//dRIKxWL0tRbEhYXFxc4Pj5GNBrF8fExkskkfD7fve6Xj05Y\n0EvbZDLxA6XRvhqNBsvlEtVqlR0dqaiFWhmVC0X5qzJkS5XpVEhGyv7k5ASnp6c4OTnh0CPln5Xf\nZxdRmrJQa9tgMGCPD/JHoAjR2yCXzePjY7YQpqp3QT3m8zna7Tby+Tzy+TwLaMrlN5tNjEYjZLNZ\nZLNZVCoVfmFtNhuORJAQoToJcumkOiPqMHmftUE5Y6qbms/nbKg2Go14dsa7htQ9ZigVYrPZeBIy\n1YyRkKMWUuoGUKJ8FmQLrvTWUXZZ0TCzcDiMUCjEc3feZrol/A5FLHw+H5bLJUajEQ/rq1arcLvd\nXNxPaTzlwVN5f19n2Q7glQ6fSqWCUqmE29tblEoltmA3Go0IhUI4OTlha4P7jO4+OmFBUPeHz+fj\nhUj+EbVabatNlOokyICJCjip0EXZ4mY2m+F2u3k0MW2KdrudF5/P53vFeGRXBQWh9C4gm/NCoYBM\nJoOzszNUq1WMRiPMZrOtIWOvg+YfKKNMu35/Pzc0I4TmtWg0Gm4Fpc4PAGxFrxzfTePq6SWmjFiQ\nKHxfh9TRaIR4PM7rlaKKdrsdsVgMsVgMgUDgq+5WoMONw+HAcrnEwcEBut0uNpsNp5+oo4MuJXq9\nnov3lF02Pp+POxeojZTqwSgy8j6mW8LvaLVaWCwWeDweaLVajnxT6qNWq6HT6bD3ks/ng9PpZJGn\nTFXcFRbK6PlgMMBgMECn09kaFjccDmG1WvHkyRN2dSa7fUpn3hePUlgoW0/pJe/xeBAOh5FMJlGv\n1zl8Sxe1yNELkDpMqOBJaQMei8UQj8cRjUY5LHj3Il8NCc3/jjL9MRgMeH7Ky5cvUalUUKlUMBwO\nX2ucdJfXCQvh80KTgufzOWazGSaTCZrNJvb29jhKQW2JFEKPx+OIxWKIRCLsFaNsFTYYDG+dd/E6\nqA2VBAX9qtfrOUJIPiZf6wA0EhZ03w4ODrBcLmEymbhgllpP6eVz1yDJZrPB5XLB7/cjFArxZFoS\nZ9RdRX4h9LxEVLw/Go2GU0YUtaN3SqFQ4Gfl9Xq5RojmrQSDQRZyrxsyRx1TlGKp1+uoVCq4ublB\nNptFqVSC1+uF1+vF/v4+UqkUW+7fl3eFkkcnLJQ3ixYD9WD7/X7eEH0+HwsGiiwYjUYuKqSWVL/f\nD6/Xy6csl8uFg4MDnkehjGbIgns7So8CKhzrdDpYLBYwGo3weDzv9X2oOE9ZrCn3Xn3IeI6idnT6\npejFeDzm/09OfrFYDIeHhzg4OOB1Qvb5r3Pl/BSUvhnk7UBi5WtGo9HwvdTpdIhEIgB+75ay2+0s\nOqjFngYeEk6nEx6PB16vF6FQiNMdysvpdL6SEhY+DHqnUDEsRc4dDgcXRrdaLY5kkHindXbXwp6g\nQ5pSWNAYBKp16na7LFCOj49xdHSESCQCr9f7INbHoxMWb4I2yc1mA5fLxT29Ho8HsVgMp6envADX\n6/XWTA+l3wS1Onq9Xm7XeQgP6qFDOVm9Xg+Hw4GjoyNsNhtEo1F2MZ3P5+/1vU5PT3F0dMThc9n4\nPg8GgwFutxuxWAz9fh/tdhudTger1YrTgZTjV3ZF0amLQru0RtTO5yodKAHsZEpsb2+POw90Oh1H\naQ8ODnhdUSSWoBQIFX/Sc6S6sPs+zX6tGI1G2O12aLVapNNpnruyXq85+jQej5HNZnFzc/Ne35Pc\ncUmcUBpwvV5jf3+fr2AwCIfD8WCe61cnLOgBkqigNjkyhFF6upP9N50M6NSlNBeRdqv3g14CWq0W\nTqcTR0dH8Hq9GA6HXHz0vsV2brcbPp+PI00PZbF8bdwVFgDYgIlCrIlEglODNKbebrezOROlBT+H\nAKRKelp/u/hZoM4DvV7P9vYkKihFdbdmSRk9olSH8tevtTblPqFoBdX+UUQ8nU6zYCevi2q1imq1\nislksjWRFPhjgBkV31IXJKXp/X4/R9bJ4iAYDMJisbx359WX4KsSFrQBkXIUvhxKlzmdTger1Ypo\nNHrPfyrhbdBQv0QiwaZY8/kcy+US8Xic3WQPDw9xeHiISCSyFaL/3NB63rWIofLloNFo+KAjPFyU\nqToAsNlsCIfDWK1WKJVKyOfz0Gg0PEWWzOgoNa88dJGgpmgVfT+bzYZIJML1f263Gy6XC263+17+\nzm/jqxEWgiB8GCaTCcFgEMvlEna7HfF4HE+ePMFqteIOqFAoxE5+0qEjCO+Hsl3XbrcjFArxgSsQ\nCCCZTGI8Hr8SsVB+rbIYlDyTKC3p8XhgtVofbPRJhIUg7ChmsxnBYJCjS2R+tdlsuKX0S6Q8BOFr\nQ+kFQrbeTqcToVAIqVSKU47K1lJC2YJKaX1l2zal6dUullYTERaCsKNQRTsN6RMEQR2UApwE+i4h\nVSxNPkIAACAASURBVImCIAiCIKiGCAtBEARBEFRDhIUgCIIgCKohwkIQBEEQBNUQYSEIgiAIgmqI\nsBAEQRAEQTVEWAiCIAiCoBqaf/zjH5t3/zZBEARBEIR3IxELQRAEQRBUQ4SFIAiCIAiqIcJCEARB\nEATVEGEhCIIgCIJqiLAQBEEQBEE1RFgIgiAIgqAaIiwEQRAEQVANERaCIAiCIKiGCAtBEARBEFRD\nhIUgCIIgCKohwkIQBEEQBNUQYSEIgiAIgmqIsBAEQRAEQTVEWAiCIAiCoBoiLARBEARBUA0RFoIg\nCIIgqIYIC0EQBEEQVEOEhSAIgiAIqiHCQhAEQRAE1RBhIQiCIAiCaoiwEARBEARBNURYCIIgCIKg\nGiIsBEEQBEFQDREWgiAIgiCohggLQRAEQRBUQ4SFIAiCIAiqIcJCEARBEATVEGEhCIIgCIJqiLAQ\nBEEQBEE1RFgIgiAIgqAaIiwEQRAEQVANERaCIAiCIKiGCAtBEARBEFRDhIUgCIIgCKohwkIQBEEQ\nBNUQYSEIgiAIgmqIsBAEQRAEQTVEWAiCIAiCoBoiLARBEARBUA0RFoIgCIIgqIYIC0EQBEEQVEOE\nhSAIgiAIqiHCQhAEQRAE1RBhIQiCIAiCaoiwEARBEARBNURYCIIgCIKgGiIsBEEQBEFQDREWgiAI\ngiCohggLQRAEQRBUQ4SFIAiCIAiqIcJCEARBEATVEGEhCIIgCIJqiLAQBEEQBEE1RFgIgiAIgqAa\nIiwEQRAEQVANERaCIAiCIKiGCAtBEARBEFRDhIUgCIIgCKohwkIQBEEQBNUQYSEIgiAIgmqIsBAE\nQRAEQTVEWAiCIAiCoBoiLARBEARBUA0RFoIgCIIgqIYIC0EQBEEQVEOEhSAIgiAIqiHCQhAEQRAE\n1RBhIQiCIAiCaoiwEARBEARBNURYCIIgCIKgGiIsBEEQBEFQDREWgiAIgiCohggLQRAEQRBUQ4SF\nIAiCIAiqIcJCEARBEATVEGEhCIIgCIJqiLAQBEEQBEE1RFgIgiAIgqAaIiwEQRAEQVANERaCIAiC\nIKiGCAtBEARBEFRDhIUgCIIgCKohwkIQBEEQBNUQYSEIgiAIgmqIsBAEQRAEQTVEWAiCIAiCoBoi\nLARBEARBUA0RFoIgCIIgqIYIC0EQBEEQVEOEhSAIgiAIqiHCQhAEQRAE1RBhIQiCIAiCaoiwEARB\nEARBNURYCIIgCIKgGiIsBEEQBEFQDREWgiAIgiCohggLQRAEQRBUQ4SFIAiCIAiqIcJCEARBEATV\nEGEhCIIgCIJqiLAQBEEQBEE1RFgIgiAIgqAaIiwEQRAEQVANERaCIAiCIKiGCAtBEARBEFRDhIUg\nCIIgCKohwkIQBEEQBNUQYSEIgiAIgmqIsBAEQRAEQTVEWAiCIAiCoBoiLARBEARBUA0RFoIgCIIg\nqIYIC0EQBEEQVEOEhSAIgiAIqiHCQhAEQRAE1RBhIQiCIAiCaoiwEARBEARBNURYCIIgCIKgGiIs\nBEEQBEFQDREWgiAIgiCohggLQRAEQRBUQ4SFIAiCIAiqIcJCEARBEATV0N3XD/773/9+Xz/6q+af\n//znJ329PJfPhzybh4k8l4eLPJuHy9uejUQsBEEQBEFQDREWgiAIgiCohggLQRAEQRBUQ4SFIAiC\nIAiqIcJCEARBEATVEGEhCIIgCIJq3Fu7qSAomc1mfG02G75WqxWWyyWWyyXm8zlmsxmm0ylWqxV/\nrU6ng9lshtlshslkgl6v37p0Oh30ev09/u0EQRB2BxEWwoNgPB6j2+2i2+1iuVxivV5jvV5jNpth\nMplgMpmg2+2i3W6j3W5jOp3y11osFgSDQQQCAXi9XlitVthsNthsNv5nERaCIAhfBhEWwoNgMpmg\n1WqhUqlgPp9jtVphtVphOByi3++j1+uhWq2iWCzi9vYWg8GAv9blciGVSiGZTCIej8Pr9cLj8cDr\n9WKz2cBgMMBisdzj304QBGF3EGEh3AubzQbj8RiTyQTj8RiFQgGFQgG3t7eYzWZYr9dYrVYYjUYY\nDAbo9/uo1+sol8solUoYjUb8vTqdDgBguVxiNBrB5/PB5/Oh1+thsVjAYDDAbrdDo9HwJXx51us1\np7gGgwF6vR56vR70ej2sViusViuMRiOnsPb29u77j/wo2Ww2/OtiscB0OuUUIl3r9Ro6nQ46nQ4G\ng4Hvv9lslnUifDIiLIR7Yb1eo9PpoFKpoFKpIJfLIZ/PI5/PY7FYcCpkPp/zZkgvo+VyubXpLRYL\ntNttaDQaDIdDuN1uuN1uBINBrNdr2Gw2+Hw+7O3tQavVygvrniCxuFqtUCqVcH5+jouLC9jtdsTj\nccRiMXi9XjgcDjgcDnlOnwAJuPF4jEajwVez2USj0cB8PofVaoXFYoHH4+H7HwwGZZ0In4wIC+Fe\n2Gw26HQ6yGazOD8/RzabRS6XQzabxXK55FOX8mW0XC6xWCywXC63vhcJi+FwiHq9DqfTCafTiWaz\nCbvdjkgkgsVigc1mI7UW98hms+FnWCqV8H//93/417/+BZ/Phz/96U/83LVaLaxW633/cR8tJCrW\n6zVGoxGq1Sqy2Syy2Sxubm6QzWYxHo9ZgMdiMUynU1gsFni9XgCQaIXwSYiwEL4Y6/Waow/D4RCF\nQgGZTAZnZ2coFosoFosol8tbHR9arZZPT3t7ezCZTLDZbNBoNBzVWK1WWCwWGA6HGA6HmEwmGAwG\nWCwW2N/fR7PZRK/Xg9lshsVigU4nH/v7YLVacQSq3W6jWCzi8vISw+EQoVAIw+EQs9lsS1gKHw6J\nCkol1mo1ZDIZXFxcsMBQCovJZAKPx4NoNIpwOAyTyQSTySTr5BOgvWmz2XC6dzwew2AwcGG5WveX\nnjddlMbSarVbKa0vKRblkyN8MVarFVqtFmq1GiqVCs7OznB5eYlsNotOp4PRaPTKC4XEhMlkgtVq\nhd1uh91uh1arxXw+x2KxwHg85nz9bDbDfD6HRqNBv9/nn1cul+HxeKDRaGA2m+/pDuw2y+WSReVk\nMtmKUBgMBphMJhiNRuh0OjkxfwLUpk3Fz7VaDTc3N8jlcmi1WlwcPR6PodFoYLFYOEXSarXgdDp5\n3QkfhzLCWiqVuIbM7/fj6OgIR0dHsNlsqv28xWLB7fhUO6PX6/lQptV+WcsqERbCF2O1WqHdbuPm\n5gYXFxe4vr7G9fU1stksC4L1er31NeRRYbfb4fF4EAgE4Pf7odPp+CTQ7Xah0WgwnU4xmUx449Tp\ndFvCgjZR4X5YLpeYzWYsLBaLBYDfxaNer4fZbBZhoQJ0gqViZhIW+XyeCznX6zU/A4PBwPUXzWYT\nWq1WxPcnoozOlUolPH/+HD/99BOOjo6wt7eHaDSqqrBYLpcYj8cYjUYs0gHwWvrSxbgiLITPitLs\najabodVqIZ/P4+zsDLe3tyiVSryZ0cnVaDTy6dVut3Mxn9/vRzAYRCgUgk6n44XUaDS4UG08HmO9\nXmOxWGAymWA4HLL/hdPpxHw+v+9bsrPQ5tfv9zEej7FYLKDRaKDX6zkiZTabYTAYvvgJ67Gj7ASZ\nz+cYDAYYDoeoVquo1WqoVqtotVpbv5+Ko+n3DgYDjEYjTKfTV+qYhA+DIqkUMcrlcnj58iU0Gg2O\nj49ZVKsFCfZ2u721h1L690vXLImwED4r/1975/ncRrpc/QMSOc4Ag5wIMGlLWsl7Xa51+Z/3B5er\n7GuXN+muAkUSIEDkMBjk/H7Yt1sPwCBKAvPzq0JpS9JKEAYzc6b79Gky7NHTU6vVQqlUQj6fR7PZ\n5LFRurnYbDZEo1HEYjHE43F4vV44nU44nU54vV4oisKlWkrqrFQqAP7KwqCxuuFwCADsv5hMJhy8\nJbkf6GLbbrfR6/Uwm82wtbUFm80Gt9sNRVHg9Xpht9ulsPhKRMOmruvsWXr37h0qlQrG4/F9v8Vn\nxXg85lasruvo9/srwX+bZjgc8rUV+OxN0zQNkUgENpvtTqd8pLCQ3CokLEajEfr9PprNJkqlEnK5\nHBs5AfAsvcfjQTabxevXr/H69Wv4fD5YrVZW4aTETSYT9zFLpRKfWOS1oP49lYSlsLh/JpMJV5D6\n/T6m0+mKIVdVVXi9XpjNZiksvhLRsKnrOnK5HN6+fYujoyOUy+WVpFrJ7UPColarod1uYzAY8PXn\nNozJorAQAwZTqRSsVis0TYPNZtv433sVj1pY0EESRxLn8/mKMxbAyo80XUCO2fVfl73dzULCYjKZ\ncBm82WyiVqvx5202m+F2uxEMBhEMBrG/v48ff/wR//Iv/8J5BnTM6EWCgY653++H2+3mgCX6PeSO\n3t7elsf3HhBbYRTLXqlU0Ol0sFgs4HQ62ZDrdrulB+YrEK93VJWbTqeoVCrI5XJ49+4dzs7O0Gg0\nrm0BktlzOp2u7OwZjUYXpgtkeNblrIuF8XiMTqezIizm8/lKy2qT0MNbt9tFt9vltrDZbEY4HF75\nu4HbnxB51MJiPp+zGanX6/HT6mQygdls5hsSnQg06uPxeOB0OleCYMSxRslmuawdQceDXul0Gru7\nu9jd3cX+/j7i8TgcDgcsFgtf3EQxOJ1OYRgGDMNAsVhEpVLhsVJ6OjCbzRwAFIlEoKqqdLrfMWIG\nSbvdRrFYxIcPH6DrOsxmM5LJJGKxGHw+nxxv/EqGwyH6/f5KOq1hGPj06ROOj49RLpfRarX4pnYV\ni8WCW1TVapXPsdlstnKOiov9JNczHA45ALDZbLL367agdOFAIIDZbMZhgt1ulz0zJCzuQhQ+6jN5\nNpthOBzCMAzU6/WVuGebzcYnA92UHA4HwuEwwuEwlsslj+SI4zmSzUIVpct8DiT0XC4XdnZ28OOP\nP+Knn35COByG3++Hw+FYcTUDn0+KyWQCXddRrVZRKBRQLpdZWNCTG+0IIWGhKIoUFneMeOybzSYK\nhQLev3+P7e1tqKqKYDCIeDzOvhnJzRmNRmi322g0GqjVaqjX66jVasjn8zg9PUWpVIJhGFwavwoa\nPSVhAXyuNFLUt9Pp5LhveZ28HqrOkbBotVro9/u3KizIpxQIBGAYBhaLBQzDQK/X423Q65X82+RR\nC4vpdIput4tGo4FisYjj42McHx/DMAxeoW21Wrki4Xa7+Wl2XY1TD99qtd7a+6UDKlZH7ivA5C4R\ny+E0Pur1euHz+aAoChRFQSaTwQ8//ICffvqJQ6yuGzucTqfodDoolUooFAqoVqucvikGxdjtdvh8\nPmiaBo/Hc6vHV3IRcexO13WUy2Wcnp5C0zSEw2Ekk0lEo1H2VkhuDk1EnZ2d4fz8nB+syuUyKpUK\n6vX6jUybJCxarRZcLhePBQ8GAz5PfT4fvF4vTCYTbDbbs7hufS2igZaEWrlcRrvdxmQy4WqPWHnd\nFBaLhQ3uFouFr49UsaBWyF0dq0d9Jg8GA07vy+VyOD8/54qFxWKB1Wrlm9PW1hbsdjsqlQpOTk5W\nTIFkHCRVfhtsb2/zzdLpdPLJSjdRats8NcQWlKZpODw8xHw+Rzgc5qchl8uFg4MDRKPRFSF4HZPJ\nBO12G+fn5ygWi7xKXVx0Jbl/SFgMBgOMRiOuWlmtViiKgng8jlAoBI/H8yS//7dJu93G8fExfvvt\nN9TrdbRaLbTbbTbH3vQJeT6fo9Pp8GbhWq0Gr9fLo970YzqdRiqV4sVldE2T/MV0OuXqHFWSqtUq\nlsslPB4PgsEgEokEFEXZ+OcmemQGgwG63S50Xb8gLO7quviovxX9fh/n5+d4+/Ytjo+P0Ww20Wg0\nMBqNVrwTpNLoaZlepCBtNhsrc4/Hcyvv1Ww28zhlIBBAPB7n1EF6AniKF1b699HxePHiBVRVxeHh\n4UqViDaS0ljUl5Q1tUJKpdIFYSF5OMznc77YicLCYrFAVVXE43GEw2EpLL6BdruNk5MT/O///i86\nnc7K9tLxeHxt+0NkNpvBMAwWGOIEFhlrPR4PmwEDgQCWy+WNz9XnArXmKbSPhIWiKNzyi8fjtyIs\nyMy+LizEVohoHJXmzWsYDoeoVqs4OjrinQO9Xu9KB/T6B0u+CqvVCr/fD1VVoSgK/36TybQxhUf9\nfqfTiXg8jsViAZfLxaOTT1X5k7Cw2WxwuVz85EMZBmJbSGwPXYaouMfjMQuLUqmEdruN0Wi0YlAS\nDZ/SyX4/rMd4U7/farXC5/MhGo0iGAzC7XZLYfEFxJbicrlEs9nEyckJfvnlFwyHw2/+flP0N2XK\nECaTiT1Q1EZUVRWpVIp//Tm3FsV7w2KxWBkiaLVaaDabqNfrcLvd8Hq92NnZudWKBbUcSVh0Oh3e\nv3PXldxHfTdzu91IpVL46aef4Pf7edRmOp1yNcJkMnGJSsxTn0wmbPKjg0K7Jqhlsb29zSONX0qi\nE/0T1NYgA9R8Psf29jbfYCeTCex2O5xOJ0wmEzRN48rJU2dra+tCzOz6xMdVTCYT9Pt9boGRr0J0\nPlPLy263IxQKwe/3w+fzweVycVy05O4wDAPn5+c4OTnB+fk5hsMhHA4H37DE4yKF3/WQmGi1Wmi1\nWjg6OkKj0Vh5Gr3pZyied+ILAHvQxARbADg9PYXVakW32+UJrmw2+yyuW1dBU0/T6RSlUom3NH/8\n+BGGYcDlciEQCCAWiyGTydzaBBTlWFCS8W2bRb/Eo77KulwupFIpLBYLRKNRGIaBTqeD+XzOfomt\nrS0MBgMuUVFVg0pFZHAhoWEYBgsAm83G89zXmaDEm6RYBSHBQv8viZXxeAyn07mSu+D1eu/qY7tX\n6OJFP36NCYyqFI1GA+fn5zwj3u12ufS7vb3NHpZgMAi/3w+v1wuXywWLxSKfiu8YGgd+9+4dCwuK\n7yZfE23SlMLiehaLBVqtFo+TUvuXbiBf8zRKrVd6iKJrE/DXeSZmW9ADUi6XQ6/XQy6Xw88//wyb\nzYZUKvVshYX4GQ0GA27L//LLL/zA43K5oGkaC4twOMzZPJt8H6KwoPHW+/SZPWphQRULRVFgGAZ0\nXYeu61gul7xfYmtri+e7O50O2u02Wq0WGo0GyuUyO3hJeIxGI77oORwO3kexXiYUEZ+8aQGM3W7n\nnhttciTG4zG3BahMFolE7uIju1foxvGtJ5Xoqzg/P1+pWNA4FbWcVFVdqVg4nc6VpzLJ3UDC4s8/\n/4RhGFyxEI27FOEthcX1LBYLNJtNHB8f43/+539wdnaGZrO54vi/af+chAWZ18Vxe9o3slwuudIL\nAN1uF7lcDgA4g+S57xQRzckkLP7jP/6DfSpOp3OlYqEoyq1sG5UViw1CccCLxYJv6i6XC8vlcqVi\nYbfb4fF4oCgKAoEAer0eDMNAMplkJzUJCKom0NMUiYovCQu6MFLktN1uR6vVQqFQQKFQ4DHI+XzO\nvUlaEPOcli597c2DVg9Pp1NUq1Wcnp7i3bt3HFVMq9bp6cvtdiMSiSCbzWJ/fx+JRIIFprxx3T7i\nyB0thut0OmyqpnN1PQFXHpvLEXftDIdDrrS22230+332k92k6kdmTAoJFMMCqWoBgIMGO50OP5AZ\nhsHvB/grQ6PT6aBarWI+n/N17zlVBMnsWq/XUalUcH5+Dl3XMZlMoGka4vE4YrEYfvjhB97Xsanr\nkOiXmM/nvIdJDEWTwuIbEScOSFT4fD4sl0tuR5hMJrhcLr45iZG1/X4fvV6PRcVVFQv6PVeVlujL\nQu+HhEUul4PVaoVhGBiPx9y3FN+v0+m88wUxjwnRaU3rn9++fYvT01M0Gg0+LrR62+PxIBqNYn9/\nHy9fvkQymWRhAciZ+7uABDRtM6WL73K55Cfk9Yh2eVwuh6oGZIClGz2NlIpG9S8JNLvdDk3TEI1G\nEQqFEAgEuFVIwmK5XLLxsNls4uzsDGdnZ+h2uyt/FkVWVyoVmEwmKIrCx/W5sFgs0Ol0UCwW2UOk\n6zpmsxkURcHu7i5ev36NTCaDSCTCD5Cb+q6TuBBzSMrlMlcGb2svyU141MKCnnqo/A3gShOTqPDE\n/SL0RHyTisV1woJeorD4/fffYRgGjo+PuUUzm83YyCma155LxeJrEdNVSVj88ccfKBQKmE6nmM1m\nXNa1WCxwu92IRqM4ODjAq1evuCUmb1x3B42+0XlFvhjyEtGT7bqokMfoIlcJC6pYUJviJlUfu92O\nYDCIbDaLnZ0dRCIRjrqnVsh8PucEz3K5DJPJxO0sEfI7VatVTjh+Lj4xgha+FQoFfPjwAcViEbqu\nYzqdwufzYW9vD//6r/+KQCAAt9vND7qbQryPiRUL8sjcJ49aWHzPBYkOCh0YmsqYTqcsDqiSQG2L\n697H+rIesYRJOe30tKYoCvx+PzRNg9/vh8vlktMKVyDenCjwZTAY8AjVYrHgHBJVVZFMJhGJRKBp\nGnw+38q+EcndQJMEolinEVPKcxHD6+SxWUVsJ43HY1SrVRSLRb6BlUolzie4zONAD1xms5mvZQ6H\nA7FYDIeHhzg4OEAqlYLf74ff7+cMEZpko4qq1WrlsCybzcbnGz2pn52dwe128zm5WCxYOK63RZ7K\nMaZJGUq2pFUSZ2dn0HUdi8WCfXNerxeKovDD4ya/68vlcmVHTK1WQ6/X4x1JdAxUVeX7y12ea8/6\nbkZiAACXqebzOat3OsG2trauzccXBQ49XYzH4ws3QTrYJCqCwSACgYAUFtcwm83Q7/fRbrdhGMal\n64ctFgt8Ph9isRjS6TQ/hclJkPthOp2i3++j0+lwuV68YZFol5MgV0NjjKPRCOfn5/jjjz/w9u1b\nThfu9Xp8g1t/OhVH230+HwKBAAKBAJLJJA4ODrC/v49oNHqpeZbMnxRcl8/n4fP5YLfbuUJIwiKX\ny/FGzfF4DJPJhHA4DFVVL4QTPhUWiwVnRbRaLVSrVTaTU/WI0kppW+9tTD0tFgt0u11UKhWUy2VU\nq1X0ej0Af1WmFEWBqqrQNA1utxtms/lO/UzP+m4mVhqoMkEnlvhrFovli8ur6GBR0AyNtZJvgyoW\nXq8XgUAAmqZxn1NuDLwasWLR6XQwHA4xnU5XjEkWi4XjoUlY0Bp1+UR891DeCPkA6OYnVv9kpsjV\niCXu4XDIwuI///M/uS3b6/X4960jtlpJUCSTSWQyGezt7WFvbw+hUIirFKLwpkRNj8cDl8uFUCjE\nwoKEx3Q6ha7rGA6HKJVKGAwGAMBLyra3t7n0DzydagXwOQjLMAw0m03UajXeV0QDA5TgLHroNv0Z\nLJdLdLtdlMtlfPr0CZVKhb8TDocDqqquhM/d1o6Sq3i2Z/b6B3zVB36TAyGm4fV6PZyfn+Ps7Ayf\nPn1CrVbDeDzm2OpkMolsNotIJAKPx7NRp/BTgUp8vV4PxWKRQ2fy+TxarRYmk8lKPHskEsHOzg52\nd3eRyWQQCoXgcrlkpeIeoBsPVZlEg6HT6YSmadzflzHeV0OigTxGNFlDIX/rSYpiDLff70cwGEQo\nFEI4HEY0GkU0GkUsFkM0GoWiKCwC1q899OdR9VbTNCQSCezv76PRaKDZbGI8HnOw4Gg04mktWn61\ntbUFRVH42vaUrm+LxQK9Xg+NRgOlUgn1ep3j1Kk6RBu0yRS7Kf+ceJ+hVky5XMbx8fFKxYIm4/b2\n9pBIJNhDc5fH4NkKi00i+jUov//XX3/F0dERSqUSf+kikQhevHiBg4MDRCIRuFwuOW53CZ1Oh8d0\nyZWez+dRLpdRr9cxmUx454qmaUin09jf38fBwQGy2SyvXJfcD5PJBL1eD+12myP2l8sl3G439/nT\n6TSXzCWXQzeR2WzGQXuU17IOtT0URUEqlUI2m8Xu7i6CwSAUReFfo+rDdTc7Sse12WzQNA3ZbBaD\nwQDHx8eYz+dotVp8vVsul2i328jlctym9Hg8SCQS8Hg8G72xPgRmsxm63S6q1SoKhQIajQZ6vR7m\n8zlcLhdPpMXj8VsxjVMlS1xpcHx8zB4LAPB4PIjH43jx4gV2dnbg9/vv3GcmhcUGEEuXuq7j9PQU\n//d//4d8Pg/DMDAajdiBfXh4iMPDQ4TDYTidTnlhvQTDMHB2dobff/8duVyOjWv0ZDCZTODz+eD3\n+5FKpbC3t4f9/X3s7+9zEuBz3mFw31ArRBQWwF8XvFgshhcvXvCTlPz+X4+Y7khu/8sc/9RXpyfV\nN2/e4M2bN9A0jasZFouFx0qvu8mImTyBQACZTAYmkwmz2QytVourGfQ+dF3HYDBAqVTC9vY2EokE\n+v0+R+zf94TCJqG9KrVaDcVicSWMyuVysXCOxWIrY+6bQKxiiWGBJycnK1lLdJ7R+1BV9c5b7VJY\nbABKXhsMBqjVamyoabVabOix2+3wer3QNG3FsCkrFX+x3k6q1+vI5/MoFAqoVCpoNpvsVTGZTHA6\nnQiFQtwCicfj0DQNHo/nSZVeHwNixY5KtLVaDYVCAbqu89OcoijQNI0NfhRgJ7nI+sIx+nxFxDju\nYDCIdDqNnZ0d7O/vY2dnB/F4HD6fb2W090uIRnTySgSDQSwWC1QqFRQKBXi9XgwGg5X9S6Jhl5KG\n73Lp1W0ixhTMZjP0ej00m01UKhXous7XJUrZTKVSCAaDcLlcGx8vHQ6H6PV6nB5NAY+LxYKvi16v\nF36/n88zeoCVFYtHxmg04pXttGmTTjwAPMpKY192u53NNJK/EEfZhsMhdF1HrVZDq9W6YADc3t6G\nx+NBOBxGNptFNptFKBTiG5VsLd099BQ1Go3QaDRQKBR4EdNyueTRRlVVeSncc0qcvQ3IoOl0OpFK\npXBwcICXL18ilUohHA7zyOf3nA92u51DB4PBIL9oJfdVrZmnhlgtoMyIer3O4YcmkwkOhwN+vx+x\nWAxut5t9LJtCrJaUSiVUq1Wu4tK0FU3I0WQKJTvf9fVQCosNQDntxWJxJVKVwrDMZvNKhLcUFhcR\n20k0BVKr1XihznQ6XQnCov0qJCzoAis/07uHnuQozZaExdHREY9uk7CgPj+Za6UA/HZoesPvKT3J\nHAAAG71JREFU9yOZTOLw8BBv3rzhp+Xv3cFiMpl4Gs5qtSIUCrGwoGNOEyFPHbEiR22+Wq3GCyxJ\nWNA0Bo2538aIabVaRT6fZ2FBwwH0fRCFhfiwdZdIYfGNrIfFlEolHB0d8WIgOtiqqkJVVezs7CAU\nCvEkiAxtWmUwGHDYy/n5Oer1+kps8Xw+562YXq8XoVCIL3RkTpKtpftDNGxSJHSj0eCQMlFQkLCW\nx+rmXNZWIJPezs4ODg4OuP1BpsnvNU7StmYal6QHI4fDwQFn4vujHB9qFSiKwq3Jx+ylEVshNAnT\n7XZ5+SG1uRVF4cWSt/HdpgwNmhCi6G7KXnI6nfweqFJxXzEGUlh8IxRZPJlMUK/Xkcvl8OeffyKX\ny6HZbGI6nSIQCGB3dxcHBwd48eIFstksj2HJm+Aq5CzP5/N49+4dz8fTWBsANpNFo1GkUilomrYS\ngiWrFffDcrnkC16tVmNBSCViSkYV4+tlu+rmXOVTCAQCODw8xN/+9jek02nE43E4HI6VMKTbeC+X\nvSjjgnb6fPr0CVtbW4jFYvw0/ZgRvS7izim32w232w1VVREOh+FyuW71PVAAY7/fX0letVgscLlc\nUFUVbrf7VrIzvgYpLL4RGvkZDodoNBrI5/P4xz/+gWq1ym0Qr9eL3d1d/Pzzz9jf30coFOJlPWLq\npwRotVo4Pj7Gr7/+ipOTE5RKJfZW0Fib3W5nc9S6sJA3qvtDFBZUaer1ehiPxwA+j0KKvgp5rL6O\nyyoWgUAABwcH+Ld/+zc26d1W6fsqQUG/BvxV4RgOh6hWqzg+PmZvmaZpG30v94Xos6B05UAggGAw\niGQyyfk5t/n3U1w+CXcSFrTUUlGUW9lL8rVIYfGNiC7oRqPB0a6GYfCq9kAggEQigYODA2QyGTid\nTl5R/NxZ39VCHpUPHz6wT4XyD6jNQf3LTCbDwsLhcDzqMutTYLlccoR9s9nkyQDawePxeBAMBrkt\nIoXF9dBTMbUHacpiHUrGpGvLphG9M8PhkF+DwYDbk+tih85niv++7Pc8VtYTmcUFmFQloH0r6//f\nt7LehiFjOxlHaZTbarXC4/EgEAjA4/FwUup9Ie9w3witDa5Wqzy5MJvNeMMmpZ/Rkh+5DOsiFPoz\nGo24L09JdrT212az8eeZSCR4vJSWKD32EutTgTwWlGlAE1EOh4MFNpkKZaXueubzOQzDQL1eR6FQ\nQLPZxHA4vJf3QpUoupnV63U0m03O5wFWN6s6nU6Ew2Hs7e0hk8lwjsZjh/6N29vbHNutqiqsVivG\n4zFntlCI2SbbfVSxnUwmnLZJKcSUXUHtRhLwXwpBu22ksPhGRqMRdF3njIV+v88bHH0+H8fpigry\nqaXQfQ90otBOlXa7zYY/WmpEewt8Ph+XG3d2djiqlkxkkvtFPJZ0gSVhQTHeyWSS9xZIcX09JCwq\nlQrOzs7QaDQwGo1uvIZgU1Alilpc9XodjUYD9Xqdd/aQv4Lez7qw8Pl8j178i1UKMklSQJ/FYlkR\nFqPRiD1hm6rMiSFpuq6jXC4jl8uxzwP4LCyo3S4rFo8IscRFwoIqFrQ2mFogyWQS8Xic16JTz+s5\nX1TFz4/CXtrtNhqNBo+WUrWCerhiKT0cDiMSiSAajULTtBuH/kg2j3gsya1OrZDBYMBtELfbDb/f\nj2g0ylHr8phdz3psdKvVwnA4vLVrx/p5Ke6joMrJ2dkZP0R1u92VrarijVdMAA2FQvc6mbBpaEqG\npkB8Ph9XXcfjMZrNJlddaYOvKKrE7bHiZ0f/Lcakiz9SW4nEHb3EP9discDhcKxMhEhh8Yigk46E\nRblcXilVivsQstkslwKfu6ggxItWu93G2dkZTk5OcHZ2Bl3XLyT20ROC1+uF1+u9dde75OaIFz4K\nDapUKuj3+9ja2uL9FLTC+SG41R8DtOiqVqvh/PychcVtsu55ouVnlUoFnz59wrt375DL5TjlUYSe\n5Gk09Smen/Rv2drags1mg9PphMvl4imNwWCAfD4Pr9cLAJywHAgEbiSkxX0wk8mE00zpv8fjMVqt\nFnK5HDqdzrXv8SF87lJYfAWimqenbTEQC1jNac9mswgGg/euHh8SorO63W7zNE0+n0e73WazFwkL\nUuK0ipiEhRRq9494E6KY4UqlgsViwcKCetF+v5+Ny/K4XQ99nvV6HcViEa1Wi/0MtwWJCvEGJ67l\n/u2339BsNqHr+gVz4tbWFiwWC6xWK1contpIseixIMOmy+XiLIlWq4V8Pg+TyYRer8fx6svl8kZm\n/fF4zG3hfr+/YpYlw6yu65cKC/FzfiiftxQWXwGdeFSqFPPip9Mpx6lSImQikXgQZamHArnMyfFO\nCY0fPnxAo9FAp9Ph/iQ99VA/MxAI8Eid9KrcP9T3pT053W6X9xdQkJLH4+FgLAqGk3yZxWKBwWCA\ndruNer3OnqPb/PtEQdHv99kvQxXFo6MjLvlTOZ+uaaLBmlayPyXxL/4bRPOm3++HruvY2triKPvF\nYsEGZjJx3qQVRCZZwzDQ7XZZYNBrMBjAMAxO+1z/XKlqRBN09319lMLiK+j3+zAMA4Zh8HKsRqOB\n8XjMe0Bo8QtlxctJkM9QJK2u62g0Gjg7O+NV6OQyp2U+dKHKZDLY3d3F/v4+ksnkvWzqk1xkuVyu\njFtTEuB4PIbL5WJvBZn35DnwcJnNZtB1fWUyq1aroVqt4ujoCOfn5xzGRMKfovXNZjPC4TASiQQS\niQRevHiBdDoNt9v9JFsiZrMZfr8f6XQai8WC/430ms/naDabODk5wWAwQKVSudE4PI31rr/EigWJ\nCxoxFaGdLuFwmMWdnAp5JNBTdrlcRrFYZGFhNpu5lxwKhXjEVFwCJPksLGhLYqFQQKlUQq1W496i\nGIQVDoeRyWSQzWaxt7eHcDgMj8cjhcUDgJ6qm80mSqUST/OMRiNsbW1xxoLX6713h7rkekhYnJ+f\nI5/PI5/PI5fL4ezsjCPax+PxyoZV8lPY7XZEo1G8ePECr169ws7ODhKJBAuLp1K1ICwWC1RV5VF4\nMl/SaodOp8NLKEmY3eTfL7YyqBpI1d3RaIThcMihXJdVr8g0Gw6H2YsmzZsPlPVkOTJU5XI5FItF\nngih/nE0GuXsCtqJIPmMKCxOT09XVqKL0IhiKpVCJpPhl6IochLkgUDCotVqsYGZSvYkLAKBALxe\nr2yBPEBEs+ZwOESz2eTFce/fv8f79+9xcnJy5f9P0xGU13NwcIB//ud/RjQahcvlgsvlepJBgNvb\n21wR8Hq9LABmsxkKhQJXFrrdLnuQbhIQZrFYeJJEfHCi3STD4ZDF3WV/nphj8b3L5zbB0zvyG0Z0\n5pbLZRwdHeGPP/5APp9Hp9Nhk1oikcDh4SF2dnZ4vlmyynw+XzFsFotFGIZx4fd5PB4kEgm8fPkS\nu7u7KwbYp/T089ihaOP1eGFxo+9D6PdKLjIajXg8slKpcKXipmZRi8XCS69o8RWZq5+yp0zcsEyZ\nHfP5HC6XC/F4HNlsFtVqFdPplMdEbyIsrFYr3G43RxMQ4/F4JZiMlp9RMNb6e3so10gpLL4AmdP6\n/T5KpRI+ffqE33//He12G91uF9vb2/D5fDwJkk6noarqk1Tr38t8Poeu67xoTNf1LwqLRCLBCZv3\nrcIln1lfiESJg8BnI5koLORxe1iMRiOUy2UcHx8jl8uhUqmgUqmgWq2i3W7fSFjQbgpa002+sqcs\nJklY0H+Hw2EWGLquQ9d1dDodbltQe/dLkEeCWodEv9/HyckJTk9Pkc/nUalUMJvNLggLMUvkIYgL\nefe7BPGLQDP6uq6vCAsKACJ/BVUsIpHIky0Dfi9UsTg7O8Off/650rMVoXXQL1++RCAQ4Bl58WS5\n6f4BMYDmup/bNOshOE8NmvBZr1jQxY0WUJnNZrnLZUNc95392u8zCYs///yTRT7dFHu9HofUXYW4\nTVNcF34bO0seEiQsxLHTSCTCEQSXvW5ybJxOJ/x+P7fViXa7jT/++IMTa+fz+bU5Fg9FxMu73xpi\nVsVisUCj0cDp6SlyuRyOjo7QbDYxn89XFCb5KtxuN+x2u5wE+U7ErIv5fP5VJT7RBHWVgLhsQ6P4\na/QjbREUI6qv+zvNZjM8Hg+XNMVfe2qIIU7FYnElJM7hcEBVVcRiMU7bfKqfw21y1XeUoLHtTqez\nMilgGAZPeFDE9Hw+XxHxuq7j06dPOD4+xvn5OY800jpuqj5dhc/nw87ODl6/fs2bm597+5fEBv03\n+SZugtVqvXShIol0u90Ol8vFi87Wochvin6nJWn3hRQWlyDe2BqNBj59+oRffvkFuVyOZ5XtdjtU\nVUUkErkgLGQI0Pchfv7Ut/8aYSGWBennxD8b+LzYZ71iIpraDMNAtVpFtVq9NvmQ/nxyyEejUb6Z\nPtXvAY2bXrYoi84NMcZb8n1cJjCoTbs+glgsFnF0dISjoyPous4eMVEskMeCxoTJS0a+gC95A3w+\nH9LpNH766ScWkFJY/CUsRFHxJYEm/r+XiQYxrpuExWXV8MVigclkgtFoxH+/FBYPDLq5zOdz1Ot1\nfPz4EX//+995nIgqFn6/H4lEApFIhJeNyYvo90PjVuS4XhcK10G/b2tra2VBEv259COJh3VhQced\nFkGVSiUcHx+j2+1e+3eaTCauUng8Hmiaxn/XUxQXYsWiUChwWqDJZILD4YDf70csFmMH/VP8DG6T\n9f0dlyFWLMQRxLOzM/z666/47//+b5TLZS7Ji6vXLzsH6BjdpHTv8/mQyWTw008/QVGUG5+fTxlq\nkQBf35oCLq9uXiYsvlSxoOTT+7z2SGGBiwuVSMnX63W8f/8exWIRuq6vjNIFg0GkUikcHh4ilUpB\nURRZqdgQzWYT79+/h8fjgdfr5RP2Jp+t2WzmgCYqLdKLBMN8Pudku16vd+EiTuKCRilLpRJHtl8G\nCQu3281PHmLs71PpO5OvYj6fryQCDgYDTCaTC9UlOmbynPg6zGYzG8IzmQzK5TJ/Z0WazSY+fvwI\nu92+MkmQz+dxcnLC2SKUqLn+9CwK7ZscI2rxud1uxONxqKp65RP0c2P989vUd16swIrnknjNIlFH\nhun7rlYAUlhcYD6fo1ar4ePHj/jw4QM+fvyIYrGIbrfLB89ms60Ii0QiAVVV7/1gPhXq9Trevn2L\nTqfD0yA3fRqy2+0IBoMIBoNcnqXpBBoBm0wmqNVqnDB4WdViuVxymZlKxV/C4/Fwr9Rut/MG1qck\nLKbTKe81IFExGo0wnU4vNeJKvh6z2QxVVZFKpbhS1u12VzZaAn+dJ//4xz/QbrdXhHe73UatVmPv\nBbU11qt34rbNm+yaID9ZJBJBMpmEz+d79lWKu+Q6v43YfqF2jMyxeCBQCb5er+Pdu3f4r//6L1Sr\nVZTLZXS7XS5Fud1uhEIhpNNp/PDDD1BV9VLjjeTbqNfr0HUd79+//+rlOi6XC+l0Gul0GrFYDHa7\nnU82GgEbjUbI5XL8Em+I69UrcZXxl6BWGMWRU3skEAh85SfwMCFhQaZWcVkSVXrkjeb7IWGRTCYx\nmUzQ7XZRKpUu/L56vY52u42PHz+unCfUQiTD5mXfXVFUiD93FSaTCV6vF/F4HPv7+0gkElAURV7z\nbpmrzOfriCbPhzA8IIXF/4duIJPJBIZhoF6v4/z8HLquo9/vYz6fcwkwFothd3cX0WgUXq9Xbm28\nIVtbW3A4HBw9OxgM+MYkQuaxb1kVPRqNuCw8GAxWNi6SiW0ymaBUKqFarULX9RVhcdUxpJOWRAqN\nGosXVrfbzVn9tHzuKV14KaWx3W6jWq2i0+lgOBxisVjw50EJgDR6SKVyeW7cHGq3apqGwWDA/i2b\nzbYidinymfiSCL+qYgFgpWVIy6wsFgs8Hg9POpFgT6fTSCQSsmJxB1zlu7js58SdJfeNFBb/H3HD\nH+VW1Ot1jlIFAFVVkc1m8erVK+zv7yMSiawEwsiL5/WI/pREIsEjcd8iIK5iNptx6JZhGHzzJ48F\nPcnRvL6YNbF+YRaPJ5l1/X4/vF4veyfEuGqHw4F0Oo1kMglN055cnDV5K2hfjhikZLVa4XK54PV6\noaoqfD4f3G637MF/A9vb25xrMB6PVybOqJ23ybaTyWRiMUHHkbbTJhIJJJNJJBIJBAKBlZcUFnfL\nY/IryTMeq+ONtDaYNnCKrmlVVZHJZPC3v/0N0WiUc9nlE9nN2NragtvtRjAYRDKZBIBrTZHfgiga\nRPMgPZ3Ri0SG2GO+zCRFiFNAoVCIg4FE/4TVakUoFEI4HIamaey5eCosFosLwoJEoc1mg8fj4fX2\nVLWQ58bXQ74cEsOqqq6snadr1aYgoy0Zjn0+HxRFQSAQwMuXL/Hjjz/i5cuXXLEjc/JTq8hJNsez\nFRbiTWY6nfIkSLlcRj6fR7PZxGQyWXFCZzIZLgPSavTt7W2p2m/I1tYWFEVBOp3GeDxeKZdfZ0wi\nxNAsGq0Sd1QAnycXaEzV4XDAZrPxmNZlx4sukvR7LguX8fl8bFyjpzXaIkiQm9/n87Hf4rHP9ovH\nhCYTGo0GSqUSVyzocw4EAojH4wgEAnC73dzrlcLi66ARQ5PJBI/Hg0gkgmw2i3a7jV6vh263u2Ke\nvWm641XQ95YqEZqmIRAIIBQK4eDgAJlMBolEYqVdIiu0d8N6YON6mu9DivEWebbCAvicWTAajVAs\nFvH+/Xt8+PAB7969Q6PRgMlkgt/vRzKZRDKZxA8//IBkMglVVXlZzEM6mA8ds9kMTdPYr6JpGr++\nlDIIgANgRqMRDMNAs9lEq9W68umN9rjQhVIUECI01ur1elf8E+utEBITtLl2XTiQh4SmQh7C2Ncm\noOMym83Q7XZRq9UuCAtxBDsYDMLlcj24i91jQUxOdDgciMfj+PHHH+FwONBqtbiFSOFto9Hou4SF\n1WpFMBhENptFOp1GKBTiVzgcRjAY5GwEeslje3esZ46I4oK+Jw9N6D1bYSHmFQyHQxSLRfz222/4\n+9//ztULEha7u7t4/fo1dnd3WVjQTeMhHcyHzvb2Nj/NxmIxvuFrmnaj6YvhcMjb/WhMlJ7crvr7\nfD4f4vE4UqkUnE4nv0Q0TUMwGEQoFGLTpdVqXalskOta9GysG6XWT/SHdrJ/DyQser0e6vX6tcJC\n07QnM2J7X9B3x263IxaLwWq1IhKJoFKpoFwuo1KpwGKxYDQaXToy/TVYLBZomobd3V28evUKkUgE\n0WgUoVCIq33iQ9RT+U4/FsTAQCksHjjL5ZIXKNXrdZTLZZydnSGXy61MKrhcLoTDYWQyGUSjUSiK\ncmX6meR6xCd6j8eDxWLBT2WiKr+K0WjEpeBgMAifzwdVVa9cymOz2djFHo/H4XQ6+e8XIXFDnpnL\nhMVzRgxSojbUZDJhM67dbkc4HGYBp2marFh8B+IN3GKxwOv18h4al8sFj8fDo550U6GQsvXX1tYW\nf5+pWke5LnRcFUXB3t7ehYrFUxmTfszM53MMBgO0223U63X0ej3MZjNeAkffh2AwCKfT+WDOt2cr\nLObzOYfOFItFVCoV6LrOJygtv6LcCnHk66EcvMeMyWSC0+mEpmmwWCw3aoVQOBMJjL29vRUD4Tpm\ns5n7xoqirIyeilDuhBguI/mMmHlAJj+HwwGr1QqPx4Pt7W2kUil+rZtaJd+H2WyGw+FgoUu7WCgj\nJZFIcFuw3W6vbCq1WCy82lxV1ZUNmnSuuVwu7OzsYGdnZ8UfI7l/ZrMZdF3H+fk5Tk9P0Wg0MJ1O\nYbfbEQqFEIvFEIvFkM1m4ff7H8y96dkLi2q1ikKhgGq1ina7jX6/z0/OpPZp94MUFpuDyudWqxU+\nn49//kurocUdIpctVxKh42ez2S70iEVo1E4cG5bHeBX6TOizojFrs9kMp9OJdDqNVCqFZDLJ5XPJ\n90NVCxJ0drsdiqJgNpuxqGg0GigWiygUCigUCiiVSmy0tdlsUBQFsViMK0rJZBKKogD465yyWq0s\nOHw+H4tGyf1DwqJYLOLk5ATD4RCTyYSFxf7+Pg4PD6WwuE/EcvtoNEKr1UKxWMTx8TEqlQo6nc6F\n6GYK/VkP+3koB/CxYjKZuIJAy7skDxcSFTSlYBgGCwh64o1EIlAU5cH1ex8zVCWiKpoo2EhkhEIh\nHu+l0ji9yPwZi8WQSCRWqkoEtShpnJQEo+T+IW/TeDxmQeHxeOB0OrG3t4f9/X28ePEC4XAYHo/n\nwbRvn9W3h0ZLKV2zUqng9PQUHz9+RKlUQr/fv++3KJE8OKgVYrVaEY1G8erVK2iaxjcgm82GWCwG\nVVVXKj5SXNwuVDkymUyIRqOwWq1QVRXpdBq6rqPdbsNqtUJRFKiqClVVuTVIrarlcsnGZPJeSFP6\nw0FMK45Go/D7/VBVFZqmrfjHfD7fg2o/PithsVgseNdBp9NBpVLByckJPnz4wLPhEonkIlRhikaj\n8Hg82N3dXXGl07SN+MT0VFfGPxSovWez2TjAjfaLXGbepArTehrqehy0FIUPBzq3VFVFNBplMUHp\nvuIo/UPYEUI8K2GxXC4vJGtWKhWUSiUOVQI+n2jU25Qnm+S5In7nzWYzFEVZKaNL7g+xRbI+6SR5\nGmxvb/NW2cVigWw2i93dXaTTaZ4Kcbvd9/02L/CshAV5KzqdDlqtFrrdLobDIac5knGQyoIOh4O9\nFQ9xVlgikUgkTxdaE3B4eLgSXPbQ9/A8zHd1S1AYFgkLwzAwGo14Z8RisWAXNmUtiFsqpbCQSCQS\nyV1htVoRDofhcrkwGo04i8dut/Mm2ofIw3xXt8RyueTtpYZh8OZSyqyg0qLH42Gjk9/vh8vl4lHE\nh+K6lUgkEsnTxmKxsPH2MfGshMVVUHSuODqXyWSws7ODw8NDxOPxlSwEiUQikUgklyOFBcAJm16v\nF6qqYm9vD//0T/+EN2/e8HgW+SxkK0QikUgkkqt5dsKCxuMsFgsHX1Hrw+/3IxwOY29vD2/evMHP\nP/8s1wRLJBKJRPIVPCthYTab4fV6EY1G2aSpaRpev37N+yJ8Ph8ODg4QCoWkoJBIJBKJ5Ct5VsKC\njJnb29twu90IBoPY29tDr9dbCZGh9ge1PmSGhUQikUgkN+NZCQuqWHi93vt+KxKJRCKRPEnkiINE\nIpFIJJKNYfr3f//3q/dUSyQSiUQikXwFsmIhkUgkEolkY0hhIZFIJBKJZGNIYSGRSCQSiWRjSGEh\nkUgkEolkY0hhIZFIJBKJZGNIYSGRSCQSiWRjSGEhkUgkEolkY0hhIZFIJBKJZGNIYSGRSCQSiWRj\nSGEhkUgkEolkY0hhIZFIJBKJZGNIYSGRSCQSiWRjSGEhkUgkEolkY0hhIZFIJBKJZGNIYSGRSCQS\niWRjSGEhkUgkEolkY0hhIZFIJBKJZGNIYSGRSCQSiWRjSGEhkUgkEolkY0hhIZFIJBKJZGNIYSGR\nSCQSiWRjSGEhkUgkEolkY0hhIZFIJBKJZGNIYSGRSCQSiWRj/D9CB2ooZCJY/AAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c148e0be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_CHANNELS = 1\n",
    "IMAGE_SIZE = IMAGE_WIDTH * IMAGE_HEIGHT * IMAGE_CHANNELS\n",
    "\n",
    "N_CLASSES = 10\n",
    "\n",
    "MAX_ITERS = 150\n",
    "\n",
    "def show_images(train_images, test_images, n_images = 5):\n",
    "    (fig, ax) = plt.subplots(nrows = 2, ncols = n_images)\n",
    "    for i in range(n_images):\n",
    "        train_image = train_images[i].reshape(\n",
    "            (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        ax[0, i].imshow(train_image, cmap = 'Greys')\n",
    "        ax[0, i].set_axis_off()\n",
    "        \n",
    "        test_image = test_images[i].reshape(\n",
    "            (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        ax[1, i].imshow(test_image, cmap = 'Greys')\n",
    "        ax[1, i].set_axis_off()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Image shape {}'.format(mnist.train.images[0].shape))\n",
    "print('Total of images for training {}'.format(len(mnist.train.images)))\n",
    "print('Total of images for testing {}'.format(len(mnist.test.images)))\n",
    "show_images(mnist.train.images, mnist.test.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's start with a simple Logistic Regression model as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model_output, feed_dict = {}):\n",
    "    # number of samples for evaluation\n",
    "    n_samples = 500\n",
    "    \n",
    "    feed_dict[x] = mnist.test.images[:n_samples]\n",
    "    feed_dict[y] = mnist.test.labels[:n_samples]\n",
    "    \n",
    "    correct_predictions = tf.equal(tf.argmax(model_output, 1), \n",
    "                                  tf.argmax(y, 1))\n",
    "    accuracy_model = tf.reduce_mean(\n",
    "        tf.cast(correct_predictions, tf.float32))\n",
    "    accuracy = accuracy_model.eval(feed_dict)\n",
    "    print('Model accuracy: {}'.format(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.773273468017578.\n",
      "Iteration 10, loss = 1.8091816902160645.\n",
      "Iteration 20, loss = 1.279937505722046.\n",
      "Iteration 30, loss = 1.0558032989501953.\n",
      "Iteration 40, loss = 0.9005128145217896.\n",
      "Iteration 50, loss = 0.9314324855804443.\n",
      "Iteration 60, loss = 0.7793976664543152.\n",
      "Iteration 70, loss = 0.5887109637260437.\n",
      "Iteration 80, loss = 0.7279807329177856.\n",
      "Iteration 90, loss = 0.63612300157547.\n",
      "Iteration 100, loss = 0.6921108961105347.\n",
      "Iteration 110, loss = 0.5517216920852661.\n",
      "Iteration 120, loss = 0.6083608865737915.\n",
      "Iteration 130, loss = 0.5105845332145691.\n",
      "Iteration 140, loss = 0.9039697647094727.\n",
      "Model accuracy: 0.8539999723434448\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # a placeholder for inputs, shape = (N_samples, n_features)\n",
    "    x = tf.placeholder(tf.float32, shape = [None, IMAGE_SIZE])\n",
    "    # a placeholder for labels, shape = (N_samples, n_classes)\n",
    "    y = tf.placeholder(tf.float32, shape = [None, N_CLASSES])\n",
    "    \n",
    "    # weight matrix with shape (n_inputs, n_outputs)\n",
    "    # initialized using a normal distribution\n",
    "    W = tf.Variable(\n",
    "        tf.truncated_normal([IMAGE_SIZE, N_CLASSES], stddev = 0.1))\n",
    "    # bias vector with shape (n_outputs)\n",
    "    b = tf.Variable(tf.zeros([N_CLASSES]))\n",
    "    \n",
    "    # linear model\n",
    "    logits = tf.matmul(x, W) + b\n",
    "    loss = loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels = y, logits = logits))\n",
    "    \n",
    "    # optimization with a learning rate decay every 100 i\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.1, global_step, \n",
    "        decay_steps = 100, decay_rate = 0.96)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    optimizer = optimizer.minimize(loss, global_step = global_step)\n",
    "    \n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for iteration in range(MAX_ITERS):\n",
    "        (images, labels) = mnist.train.next_batch(BATCH_SIZE)\n",
    "        (_, iter_loss) = session.run([optimizer, loss], \n",
    "                              feed_dict = {x: images,\n",
    "                                          y: labels})\n",
    "    \n",
    "        if iteration % 10 == 0:\n",
    "            print('Iteration {}, loss = {}.'.format(\n",
    "                iteration, iter_loss))\n",
    "            \n",
    "    model = tf.nn.softmax(logits)\n",
    "    evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "It's time for convolutions..\n",
    "But, some helper methods first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a weight matrix\n",
    "def weight_matrix(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# create a bias vector\n",
    "def bias_vector(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# create a convolution kernel\n",
    "def conv2d(x, W, h_stride = 1, w_stride = 1, padding = 'SAME'):\n",
    "    return tf.nn.conv2d(x, W, \n",
    "                        # N, H, W, C\n",
    "                        strides = [1, h_stride, w_stride, 1],\n",
    "                        padding = padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 19.901287078857422.\n",
      "Iteration 10, loss = 5.528600215911865.\n",
      "Iteration 20, loss = 2.3440582752227783.\n",
      "Iteration 30, loss = 2.3064141273498535.\n",
      "Iteration 40, loss = 2.3037219047546387.\n",
      "Iteration 50, loss = 2.309481143951416.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-cbe62b1d512f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         (_, iter_loss) = session.run([optimizer, loss], \n\u001b[1;32m     50\u001b[0m                               feed_dict = {x: images,\n\u001b[0;32m---> 51\u001b[0;31m                                           y: labels})\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # a placeholder for inputs, shape = (N_samples, n_features)\n",
    "    x = tf.placeholder(tf.float32, shape = [None, IMAGE_SIZE])\n",
    "    shape = [-1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS]\n",
    "    x_image = tf.reshape(x, shape)\n",
    "    # a placeholder for labels, shape = (N_samples, n_classes)\n",
    "    y = tf.placeholder(tf.float32, shape = [None, N_CLASSES])\n",
    "    \n",
    "    conv1_channels = 32\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv1 = weight_matrix([5, 5, IMAGE_CHANNELS, conv1_channels])\n",
    "    b_conv1 = bias_vector([conv1_channels])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    \n",
    "    conv2_channels = 64\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv2 = weight_matrix([5, 5, conv1_channels, conv2_channels])\n",
    "    b_conv2 = bias_vector([conv2_channels])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "    conv2_output_size = IMAGE_HEIGHT * IMAGE_WIDTH * conv2_channels\n",
    "    shape = [-1, conv2_output_size]\n",
    "    h_conv2_flat = tf.reshape(h_conv2, shape)\n",
    "    \n",
    "    W_fc1 = weight_matrix([conv2_output_size, 1024])\n",
    "    b_fc1 = bias_vector([1024])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    W_fc2 = weight_matrix([1024, N_CLASSES])\n",
    "    b_fc2 = bias_vector([N_CLASSES])\n",
    "    \n",
    "    logits = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels = y, \n",
    "                                                logits = logits))\n",
    "    \n",
    "    # optimization with a learning rate decay every 100 i\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.1, global_step, \n",
    "        decay_steps = 100, decay_rate = 0.96)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    optimizer = optimizer.minimize(loss, global_step = global_step)\n",
    "    \n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for iteration in range(MAX_ITERS):\n",
    "        (images, labels) = mnist.train.next_batch(BATCH_SIZE)\n",
    "        (_, iter_loss) = session.run([optimizer, loss], \n",
    "                              feed_dict = {x: images,\n",
    "                                          y: labels})\n",
    "    \n",
    "        if iteration % 10 == 0:\n",
    "            print('Iteration {}, loss = {}.'.format(\n",
    "                iteration, iter_loss))\n",
    "            \n",
    "    model = tf.nn.softmax(logits)\n",
    "    evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One practice is to downsample the image while going deeper in the the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach is just the convolution reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 12.88490104675293.\n",
      "Iteration 10, loss = 2.9282734394073486.\n",
      "Iteration 20, loss = 2.3370189666748047.\n",
      "Iteration 30, loss = 2.342435836791992.\n",
      "Iteration 40, loss = 2.3318915367126465.\n",
      "Iteration 50, loss = 2.289867639541626.\n",
      "Iteration 60, loss = 2.3252999782562256.\n",
      "Iteration 70, loss = 2.3148128986358643.\n",
      "Iteration 80, loss = 2.3206863403320312.\n",
      "Iteration 90, loss = 2.314396381378174.\n",
      "Iteration 100, loss = 2.2950782775878906.\n",
      "Iteration 110, loss = 2.3102664947509766.\n",
      "Iteration 120, loss = 2.291205644607544.\n",
      "Iteration 130, loss = 2.284393548965454.\n",
      "Iteration 140, loss = 2.296868085861206.\n",
      "Model accuracy: 0.1340000033378601\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # a placeholder for inputs, shape = (N_samples, n_features)\n",
    "    x = tf.placeholder(tf.float32, shape = [None, IMAGE_SIZE])\n",
    "    shape = [-1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS]\n",
    "    x_image = tf.reshape(x, shape)\n",
    "    # a placeholder for labels, shape = (N_samples, n_classes)\n",
    "    y = tf.placeholder(tf.float32, shape = [None, N_CLASSES])\n",
    "    \n",
    "    conv1_channels = 32\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv1 = weight_matrix([5, 5, IMAGE_CHANNELS, conv1_channels])\n",
    "    b_conv1 = bias_vector([conv1_channels])\n",
    "    h_conv1 = conv2d(x_image, W_conv1, padding = 'VALID') + b_conv1\n",
    "    h_conv1 = tf.nn.relu(h_conv1)\n",
    "    \n",
    "    conv2_channels = 64\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv2 = weight_matrix([5, 5, conv1_channels, conv2_channels])\n",
    "    b_conv2 = bias_vector([conv2_channels])\n",
    "    h_conv2 = conv2d(h_conv1, W_conv2, padding = 'VALID') + b_conv2\n",
    "    h_conv2 = tf.nn.relu(h_conv2)\n",
    "    conv2_output_size = 20 * 20 * conv2_channels\n",
    "    shape = [-1, conv2_output_size]\n",
    "    h_conv2_flat = tf.reshape(h_conv2, shape)\n",
    "    \n",
    "    W_fc1 = weight_matrix([conv2_output_size, 1024])\n",
    "    b_fc1 = bias_vector([1024])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    W_fc2 = weight_matrix([1024, N_CLASSES])\n",
    "    b_fc2 = bias_vector([N_CLASSES])\n",
    "    \n",
    "    logits = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels = y, \n",
    "                                                logits = logits))\n",
    "    \n",
    "    # optimization with a learning rate decay every 100 i\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.1, global_step, \n",
    "        decay_steps = 100, decay_rate = 0.96)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    optimizer = optimizer.minimize(loss, global_step = global_step)\n",
    "    \n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for iteration in range(MAX_ITERS):\n",
    "        (images, labels) = mnist.train.next_batch(BATCH_SIZE)\n",
    "        (_, iter_loss) = session.run([optimizer, loss], \n",
    "                              feed_dict = {x: images,\n",
    "                                          y: labels})\n",
    "    \n",
    "        if iteration % 10 == 0:\n",
    "            print('Iteration {}, loss = {}.'.format(\n",
    "                iteration, iter_loss))\n",
    "            \n",
    "    model = tf.nn.softmax(logits)\n",
    "    evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other one is using stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 6.135409355163574.\n",
      "Iteration 10, loss = 2.80208420753479.\n",
      "Iteration 20, loss = 2.321885108947754.\n",
      "Iteration 30, loss = 2.2677741050720215.\n",
      "Iteration 40, loss = 2.309001922607422.\n",
      "Iteration 50, loss = 2.2655246257781982.\n",
      "Iteration 60, loss = 2.2895140647888184.\n",
      "Iteration 70, loss = 2.1628754138946533.\n",
      "Iteration 80, loss = 2.0074026584625244.\n",
      "Iteration 90, loss = 1.58643639087677.\n",
      "Iteration 100, loss = 1.5769842863082886.\n",
      "Iteration 110, loss = 0.9109978675842285.\n",
      "Iteration 120, loss = 0.32539913058280945.\n",
      "Iteration 130, loss = 0.24121397733688354.\n",
      "Iteration 140, loss = 0.45771217346191406.\n",
      "Model accuracy: 0.8960000276565552\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # a placeholder for inputs, shape = (N_samples, n_features)\n",
    "    x = tf.placeholder(tf.float32, shape = [None, IMAGE_SIZE])\n",
    "    shape = [-1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS]\n",
    "    x_image = tf.reshape(x, shape)\n",
    "    # a placeholder for labels, shape = (N_samples, n_classes)\n",
    "    y = tf.placeholder(tf.float32, shape = [None, N_CLASSES])\n",
    "    \n",
    "    conv1_channels = 32\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv1 = weight_matrix([5, 5, IMAGE_CHANNELS, conv1_channels])\n",
    "    b_conv1 = bias_vector([conv1_channels])\n",
    "    h_conv1 = conv2d(x_image, W_conv1, \n",
    "                     h_stride = 2, w_stride = 2) + b_conv1\n",
    "    h_conv1 = tf.nn.relu(h_conv1)\n",
    "    \n",
    "    conv2_channels = 64\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv2 = weight_matrix([5, 5, conv1_channels, conv2_channels])\n",
    "    b_conv2 = bias_vector([conv2_channels])\n",
    "    h_conv2 = conv2d(h_conv1, W_conv2, \n",
    "                     h_stride = 2, w_stride = 2) + b_conv2\n",
    "    h_conv2 = tf.nn.relu(h_conv2)\n",
    "    conv2_output_size = tf.to_int32(np.prod(h_conv2.shape[1:]))\n",
    "    shape = [-1, conv2_output_size]\n",
    "    h_conv2_flat = tf.reshape(h_conv2, shape)\n",
    "    \n",
    "    W_fc1 = weight_matrix([conv2_output_size, 1024])\n",
    "    b_fc1 = bias_vector([1024])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    W_fc2 = weight_matrix([1024, N_CLASSES])\n",
    "    b_fc2 = bias_vector([N_CLASSES])\n",
    "    \n",
    "    logits = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels = y, \n",
    "                                                logits = logits))\n",
    "    \n",
    "    # optimization with a learning rate decay every 100 i\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.1, global_step, \n",
    "        decay_steps = 100, decay_rate = 0.96)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    optimizer = optimizer.minimize(loss, global_step = global_step)\n",
    "    \n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for iteration in range(MAX_ITERS):\n",
    "        (images, labels) = mnist.train.next_batch(BATCH_SIZE)\n",
    "        (_, iter_loss) = session.run([optimizer, loss], \n",
    "                              feed_dict = {x: images,\n",
    "                                          y: labels})\n",
    "    \n",
    "        if iteration % 10 == 0:\n",
    "            print('Iteration {}, loss = {}.'.format(\n",
    "                iteration, iter_loss))\n",
    "            \n",
    "    model = tf.nn.softmax(logits)\n",
    "    evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the last one is pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], \n",
    "        strides = [1, 2, 2, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 5.736741065979004.\n",
      "Iteration 10, loss = 2.7209153175354004.\n",
      "Iteration 20, loss = 2.3089687824249268.\n",
      "Iteration 30, loss = 2.29597544670105.\n",
      "Iteration 40, loss = 2.2919692993164062.\n",
      "Iteration 50, loss = 2.3028197288513184.\n",
      "Iteration 60, loss = 2.298797130584717.\n",
      "Iteration 70, loss = 2.311149835586548.\n",
      "Iteration 80, loss = 2.2998995780944824.\n",
      "Iteration 90, loss = 2.3090803623199463.\n",
      "Iteration 100, loss = 2.3364920616149902.\n",
      "Iteration 110, loss = 2.3085689544677734.\n",
      "Iteration 120, loss = 2.3041059970855713.\n",
      "Iteration 130, loss = 2.287680149078369.\n",
      "Iteration 140, loss = 2.3003664016723633.\n",
      "Model accuracy: 0.0860000029206276\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # a placeholder for inputs, shape = (N_samples, n_features)\n",
    "    x = tf.placeholder(tf.float32, shape = [None, IMAGE_SIZE])\n",
    "    shape = [-1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS]\n",
    "    x_image = tf.reshape(x, shape)\n",
    "    # a placeholder for labels, shape = (N_samples, n_classes)\n",
    "    y = tf.placeholder(tf.float32, shape = [None, N_CLASSES])\n",
    "    \n",
    "    conv1_channels = 32\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv1 = weight_matrix([5, 5, IMAGE_CHANNELS, conv1_channels])\n",
    "    b_conv1 = bias_vector([conv1_channels])\n",
    "    h_conv1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "    h_conv1 = tf.nn.relu(h_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    \n",
    "    conv2_channels = 64\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv2 = weight_matrix([5, 5, conv1_channels, conv2_channels])\n",
    "    b_conv2 = bias_vector([conv2_channels])\n",
    "    h_conv2 = conv2d(h_pool1, W_conv2) + b_conv2\n",
    "    h_conv2 = tf.nn.relu(h_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    \n",
    "    pool2_output_size = tf.to_int32(np.prod(h_pool2.shape[1:]))\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, pool2_output_size])\n",
    "    \n",
    "    W_fc1 = weight_matrix([pool2_output_size, 1024])\n",
    "    b_fc1 = bias_vector([1024])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    W_fc2 = weight_matrix([1024, N_CLASSES])\n",
    "    b_fc2 = bias_vector([N_CLASSES])\n",
    "    \n",
    "    logits = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels = y, \n",
    "                                                logits = logits))\n",
    "    \n",
    "    # optimization with a learning rate decay every 100 i\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.1, global_step, \n",
    "        decay_steps = 100, decay_rate = 0.96)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    optimizer = optimizer.minimize(loss, global_step = global_step)\n",
    "    \n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for iteration in range(MAX_ITERS):\n",
    "        (images, labels) = mnist.train.next_batch(BATCH_SIZE)\n",
    "        (_, iter_loss) = session.run([optimizer, loss], \n",
    "                              feed_dict = {x: images,\n",
    "                                          y: labels})\n",
    "    \n",
    "        if iteration % 10 == 0:\n",
    "            print('Iteration {}, loss = {}.'.format(\n",
    "                iteration, iter_loss))\n",
    "            \n",
    "    model = tf.nn.softmax(logits)\n",
    "    evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to make some final adjustements with regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 13.113471984863281.\n",
      "Iteration 10, loss = 9.921027183532715.\n",
      "Iteration 20, loss = 9.410436630249023.\n",
      "Iteration 30, loss = 9.34052562713623.\n",
      "Iteration 40, loss = 9.342385292053223.\n",
      "Iteration 50, loss = 9.328804969787598.\n",
      "Iteration 60, loss = 9.322479248046875.\n",
      "Iteration 70, loss = 9.302661895751953.\n",
      "Iteration 80, loss = 9.311676025390625.\n",
      "Iteration 90, loss = 9.299919128417969.\n",
      "Iteration 100, loss = 9.285455703735352.\n",
      "Iteration 110, loss = 9.29184341430664.\n",
      "Iteration 120, loss = 9.28366756439209.\n",
      "Iteration 130, loss = 9.262125015258789.\n",
      "Iteration 140, loss = 9.282629013061523.\n",
      "Model accuracy: 0.10999999940395355\n"
     ]
    }
   ],
   "source": [
    "beta = 0.0005\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # a placeholder for inputs, shape = (N_samples, n_features)\n",
    "    x = tf.placeholder(tf.float32, shape = [None, IMAGE_SIZE])\n",
    "    shape = [-1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS]\n",
    "    x_image = tf.reshape(x, shape)\n",
    "    # a placeholder for labels, shape = (N_samples, n_classes)\n",
    "    y = tf.placeholder(tf.float32, shape = [None, N_CLASSES])\n",
    "    \n",
    "    conv1_channels = 32\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv1 = weight_matrix([5, 5, IMAGE_CHANNELS, conv1_channels])\n",
    "    b_conv1 = bias_vector([conv1_channels])\n",
    "    h_conv1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "    h_conv1 = tf.nn.relu(h_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    \n",
    "    conv2_channels = 64\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv2 = weight_matrix([5, 5, conv1_channels, conv2_channels])\n",
    "    b_conv2 = bias_vector([conv2_channels])\n",
    "    h_conv2 = conv2d(h_pool1, W_conv2) + b_conv2\n",
    "    h_conv2 = tf.nn.relu(h_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    \n",
    "    pool2_output_size = tf.to_int32(np.prod(h_pool2.shape[1:]))\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, pool2_output_size])\n",
    "    \n",
    "    W_fc1 = weight_matrix([pool2_output_size, 1024])\n",
    "    b_fc1 = bias_vector([1024])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    W_fc2 = weight_matrix([1024, N_CLASSES])\n",
    "    b_fc2 = bias_vector([N_CLASSES])\n",
    "    \n",
    "    logits = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels = y, \n",
    "                                                logits = logits))\n",
    "    \n",
    "    regularization = (tf.nn.l2_loss(W_conv1) + tf.nn.l2_loss(W_conv2) +\n",
    "        tf.nn.l2_loss(W_fc1) + tf.nn.l2_loss(W_fc2))\n",
    "    \n",
    "    loss = tf.reduce_mean(loss + beta * regularization)\n",
    "    \n",
    "    # optimization with a learning rate decay every 100 iterations\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.1, global_step, \n",
    "        decay_steps = 100, decay_rate = 0.96)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    optimizer = optimizer.minimize(loss, global_step = global_step)\n",
    "    \n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for iteration in range(MAX_ITERS):\n",
    "        (images, labels) = mnist.train.next_batch(BATCH_SIZE)\n",
    "        (_, iter_loss) = session.run([optimizer, loss], \n",
    "                              feed_dict = {x: images,\n",
    "                                          y: labels})\n",
    "    \n",
    "        if iteration % 10 == 0:\n",
    "            print('Iteration {}, loss = {}.'.format(\n",
    "                iteration, iter_loss))\n",
    "            \n",
    "    model = tf.nn.softmax(logits)\n",
    "    evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, dropout..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 21.168779373168945.\n",
      "Iteration 10, loss = 8.899328231811523.\n",
      "Iteration 20, loss = 8.624317169189453.\n",
      "Iteration 30, loss = 8.663700103759766.\n",
      "Iteration 40, loss = 8.69107437133789.\n",
      "Iteration 50, loss = 8.64013957977295.\n",
      "Iteration 60, loss = 8.590255737304688.\n",
      "Iteration 70, loss = 8.670904159545898.\n",
      "Iteration 80, loss = 8.604418754577637.\n",
      "Iteration 90, loss = 8.580488204956055.\n",
      "Iteration 100, loss = 8.3804931640625.\n",
      "Iteration 110, loss = 8.392279624938965.\n",
      "Iteration 120, loss = 7.866387367248535.\n",
      "Iteration 130, loss = 7.814747333526611.\n",
      "Iteration 140, loss = 7.19762659072876.\n",
      "Model accuracy: 0.7940000295639038\n"
     ]
    }
   ],
   "source": [
    "beta = 0.0005\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # a placeholder for inputs, shape = (N_samples, n_features)\n",
    "    x = tf.placeholder(tf.float32, shape = [None, IMAGE_SIZE])\n",
    "    shape = [-1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS]\n",
    "    x_image = tf.reshape(x, shape)\n",
    "    # a placeholder for labels, shape = (N_samples, n_classes)\n",
    "    y = tf.placeholder(tf.float32, shape = [None, N_CLASSES])\n",
    "    \n",
    "    conv1_channels = 32\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv1 = weight_matrix([5, 5, IMAGE_CHANNELS, conv1_channels])\n",
    "    b_conv1 = bias_vector([conv1_channels])\n",
    "    h_conv1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "    h_conv1 = tf.nn.relu(h_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    \n",
    "    conv2_channels = 64\n",
    "    # convolution W matrix [k_h, k_w, input_n_c, n_c]\n",
    "    W_conv2 = weight_matrix([5, 5, conv1_channels, conv2_channels])\n",
    "    b_conv2 = bias_vector([conv2_channels])\n",
    "    h_conv2 = conv2d(h_pool1, W_conv2) + b_conv2\n",
    "    h_conv2 = tf.nn.relu(h_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    \n",
    "    pool2_output_size = tf.to_int32(np.prod(h_pool2.shape[1:]))\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, pool2_output_size])\n",
    "    \n",
    "    W_fc1 = weight_matrix([pool2_output_size, 1024])\n",
    "    b_fc1 = bias_vector([1024])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    \n",
    "    W_fc2 = weight_matrix([1024, N_CLASSES])\n",
    "    b_fc2 = bias_vector([N_CLASSES])\n",
    "    \n",
    "    logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels = y, \n",
    "                                                logits = logits))\n",
    "    \n",
    "    regularization = (tf.nn.l2_loss(W_conv1) + tf.nn.l2_loss(W_conv2) +\n",
    "        tf.nn.l2_loss(W_fc1) + tf.nn.l2_loss(W_fc2))\n",
    "    \n",
    "    loss = tf.reduce_mean(loss + beta * regularization)\n",
    "    \n",
    "    # optimization with a learning rate decay every 100 iterations\n",
    "    global_step = tf.Variable(0)\n",
    "    learning_rate = tf.train.exponential_decay(0.1, global_step, \n",
    "        decay_steps = 100, decay_rate = 0.96)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    optimizer = optimizer.minimize(loss, global_step = global_step)\n",
    "    \n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for iteration in range(MAX_ITERS):\n",
    "        (images, labels) = mnist.train.next_batch(BATCH_SIZE)\n",
    "        (_, iter_loss) = session.run([optimizer, loss], \n",
    "                              feed_dict = {x: images,\n",
    "                                          y: labels,\n",
    "                                          keep_prob: 0.5})\n",
    "    \n",
    "        if iteration % 10 == 0:\n",
    "            print('Iteration {}, loss = {}.'.format(\n",
    "                iteration, iter_loss))\n",
    "            \n",
    "    model = tf.nn.softmax(logits)\n",
    "    evaluate(model, {keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
