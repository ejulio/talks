{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este exemplo é baseado nos tutoriais disponíveis na página do TensorFlow (https://www.tensorflow.org/get_started/mnist/beginners e https://www.tensorflow.org/get_started/mnist/pros)\n",
    "e também no TensorBoard https://www.youtube.com/watch?v=eBbEDRsCmv4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import TensorFlow and MNIST\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "\n",
    "# carrega os dados do MNIST com os labels no formato \"one-hot vector\"\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos algumas constantes\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_CHANNELS = 1\n",
    "IMAGE_SIZE = IMAGE_WIDTH * IMAGE_HEIGHT * IMAGE_CHANNELS\n",
    "\n",
    "N_CLASSES = 10\n",
    "MAX_ITERS = 201\n",
    "BATCH_SIZE = 64\n",
    "LOGDIR='/home/vitor/mnist/'\n",
    "if not os.path.exists(LOGDIR):\n",
    "    os.makedirs(LOGDIR)\n",
    "n_samples = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.2971906661987305.\n",
      "Test Accuracy: 0.1416015625\n",
      "Iteration 10, loss = 1.9405230283737183.\n",
      "Test Accuracy: 0.5166015625\n",
      "Iteration 20, loss = 1.2566112279891968.\n",
      "Test Accuracy: 0.68359375\n",
      "Iteration 30, loss = 1.137709617614746.\n",
      "Test Accuracy: 0.7373046875\n",
      "Iteration 40, loss = 0.9332016706466675.\n",
      "Test Accuracy: 0.75390625\n",
      "Iteration 50, loss = 0.6738575100898743.\n",
      "Test Accuracy: 0.794921875\n",
      "Iteration 60, loss = 0.8592527508735657.\n",
      "Test Accuracy: 0.814453125\n",
      "Iteration 70, loss = 0.7975035905838013.\n",
      "Test Accuracy: 0.8173828125\n",
      "Iteration 80, loss = 0.4801229238510132.\n",
      "Test Accuracy: 0.828125\n",
      "Iteration 90, loss = 0.5498716831207275.\n",
      "Test Accuracy: 0.830078125\n",
      "Iteration 100, loss = 0.45164936780929565.\n",
      "Test Accuracy: 0.8388671875\n",
      "Iteration 110, loss = 0.6585972309112549.\n",
      "Test Accuracy: 0.8447265625\n",
      "Iteration 120, loss = 0.6582797169685364.\n",
      "Test Accuracy: 0.845703125\n",
      "Iteration 130, loss = 0.5227222442626953.\n",
      "Test Accuracy: 0.8447265625\n",
      "Iteration 140, loss = 0.5387165546417236.\n",
      "Test Accuracy: 0.853515625\n",
      "Iteration 150, loss = 0.49112868309020996.\n",
      "Test Accuracy: 0.857421875\n",
      "Iteration 160, loss = 0.570644736289978.\n",
      "Test Accuracy: 0.859375\n",
      "Iteration 170, loss = 0.469544380903244.\n",
      "Test Accuracy: 0.85546875\n",
      "Iteration 180, loss = 0.4394277334213257.\n",
      "Test Accuracy: 0.8486328125\n",
      "Iteration 190, loss = 0.44830870628356934.\n",
      "Test Accuracy: 0.861328125\n",
      "Iteration 200, loss = 0.5301057696342468.\n",
      "Test Accuracy: 0.861328125\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "with tf.name_scope('input'):\n",
    "    # um placeholder para entradas (imagens) shape=(BATCH_SIZE, n_features)\n",
    "    x = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE])\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input', x_image, 10)\n",
    "    # um placeholder para os labels, shape = (BATCH_SIZE, n_classes)\n",
    "    y = tf.placeholder(tf.float32, shape=[None, N_CLASSES])    \n",
    "\n",
    "    # pesos W\n",
    "    W = tf.Variable(\n",
    "        tf.truncated_normal([IMAGE_SIZE, N_CLASSES], stddev = 0.05))\n",
    "    # viéses b\n",
    "    b = tf.Variable(tf.zeros([N_CLASSES]))\n",
    "\n",
    "    # modelo linear\n",
    "    logits = tf.matmul(x, W) + b\n",
    "with tf.name_scope('loss'):\n",
    "    loss = loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    # SGD + momentum para otimização\n",
    "    learning_rate = 0.01\n",
    "    momentum = 0.9\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    # minimiza o valor da loss\n",
    "    optimizer = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"test_accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "summ = tf.summary.merge_all()    \n",
    "    \n",
    "# inicializa as variáveis globais\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(LOGDIR + \"linear_regression\")\n",
    "writer.add_graph(sess.graph)\n",
    "for iteration in range(MAX_ITERS):\n",
    "    # obtém o próximo batch de imagens e labels\n",
    "    (images, labels) = mnist.train.next_batch(BATCH_SIZE)\n",
    "    \n",
    "    # executa uma iteração da otimização\n",
    "    (_, iter_loss) = sess.run([optimizer, loss], \n",
    "                          feed_dict={x: images,\n",
    "                                     y: labels}) \n",
    "    \n",
    "    # avalia o modelo a cada 10 iterações\n",
    "    if iteration % 10 == 0:\n",
    "        [test_acc, s] = sess.run([test_accuracy, summ], \n",
    "                                 feed_dict={x: mnist.test.images[:n_samples], \n",
    "                                            y: mnist.test.labels[:n_samples]})\n",
    "        print('Iteration {}, loss = {}.'.format(iteration, iter_loss))\n",
    "        print('Test Accuracy: {0}'.format(test_acc))\n",
    "        writer.add_summary(s, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.4042184352874756.\n",
      "Test Accuracy: 0.1298828125\n",
      "Iteration 10, loss = 2.296656608581543.\n",
      "Test Accuracy: 0.0888671875\n",
      "Iteration 20, loss = 2.223212718963623.\n",
      "Test Accuracy: 0.087890625\n",
      "Iteration 30, loss = 2.2504281997680664.\n",
      "Test Accuracy: 0.228515625\n",
      "Iteration 40, loss = 1.8901512622833252.\n",
      "Test Accuracy: 0.380859375\n",
      "Iteration 50, loss = 1.8185174465179443.\n",
      "Test Accuracy: 0.3818359375\n",
      "Iteration 60, loss = 1.7384870052337646.\n",
      "Test Accuracy: 0.3857421875\n",
      "Iteration 70, loss = 1.7739129066467285.\n",
      "Test Accuracy: 0.4873046875\n",
      "Iteration 80, loss = 1.4763908386230469.\n",
      "Test Accuracy: 0.556640625\n",
      "Iteration 90, loss = 1.2074041366577148.\n",
      "Test Accuracy: 0.662109375\n",
      "Iteration 100, loss = 1.1129333972930908.\n",
      "Test Accuracy: 0.66796875\n",
      "Iteration 110, loss = 0.8969951272010803.\n",
      "Test Accuracy: 0.728515625\n",
      "Iteration 120, loss = 1.3609271049499512.\n",
      "Test Accuracy: 0.7509765625\n",
      "Iteration 130, loss = 0.8960660099983215.\n",
      "Test Accuracy: 0.7548828125\n",
      "Iteration 140, loss = 0.526992917060852.\n",
      "Test Accuracy: 0.791015625\n",
      "Iteration 150, loss = 0.45425891876220703.\n",
      "Test Accuracy: 0.8642578125\n",
      "Iteration 160, loss = 0.39542651176452637.\n",
      "Test Accuracy: 0.89453125\n",
      "Iteration 170, loss = 0.3683496415615082.\n",
      "Test Accuracy: 0.919921875\n",
      "Iteration 180, loss = 0.2731873691082001.\n",
      "Test Accuracy: 0.9267578125\n",
      "Iteration 190, loss = 0.40454578399658203.\n",
      "Test Accuracy: 0.91796875\n",
      "Iteration 200, loss = 0.38016968965530396.\n",
      "Test Accuracy: 0.9404296875\n"
     ]
    }
   ],
   "source": [
    "# Adiciona Convolução\n",
    "def conv_layer(input, size_in, size_out, name=\"conv\", name2=\"pool\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.05), name=\"Weights\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"Biases\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        relu = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", relu)\n",
    "\n",
    "        return relu\n",
    "\n",
    "# Adiciona Max Pooling\n",
    "def max_pool(input, name):\n",
    "    with tf.name_scope(name):\n",
    "        return tf.nn.max_pool(input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "# Adiciona totalmente conectada\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.05), name=\"Weights\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"Biases\")\n",
    "        relu = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", relu)\n",
    "\n",
    "        return relu\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "# Setup placeholders\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "\n",
    "# Redimensiona a imagem\n",
    "with tf.name_scope('input_reshape'):\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input', x_image, 10)\n",
    "\n",
    "# convoluções e max poolings\n",
    "conv1 = conv_layer(x_image, 1, 32, \"conv1\", \"pool1\")\n",
    "conv1 = max_pool(conv1, \"pool1\")\n",
    "conv2 = conv_layer(conv1, 32, 64, \"conv2\", \"pool2\")\n",
    "conv2 = max_pool(conv2, \"pool2\")\n",
    "\n",
    "# transforma a imagem em um array\n",
    "with tf.name_scope('flatten'):\n",
    "    flattened = tf.reshape(conv2, [-1, 7 * 7 * 64])\n",
    "\n",
    "# totalmente conectada 1\n",
    "fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, \"fc1\")\n",
    "\n",
    "with tf.name_scope('dropout'):\n",
    "    # dropout: elimina algumas unidades; veremos no final se der tempo\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "# totalmente conectada 2\n",
    "fc2 = fc_layer(fc1, 1024, 10, \"fc2\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=fc2, labels=y), name=\"cross_entropy\")\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    # SGD + momentum para otimização\n",
    "    learning_rate = 0.01\n",
    "    momentum = 0.9\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    # minimiza o valor da loss\n",
    "    optimizer = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"test_accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(fc2, 1), tf.argmax(y, 1))\n",
    "    test_accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"test_accuracy\", test_accuracy)\n",
    "\n",
    "summ = tf.summary.merge_all()    \n",
    "    \n",
    "# inicializa as variáveis globais\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# iniciar logger\n",
    "writer = tf.summary.FileWriter(LOGDIR + 'cnn')\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "for iteration in range(MAX_ITERS):\n",
    "    # obtém o próximo batch de imagens e labels\n",
    "    (images, labels) = mnist.train.next_batch(BATCH_SIZE)\n",
    "    \n",
    "    # executa uma iteração da otimização\n",
    "    (_, iter_loss) = sess.run([optimizer, loss], \n",
    "                          feed_dict={x: images,\n",
    "                                     y: labels,\n",
    "                                     keep_prob: 0.5})  \n",
    "    \n",
    "    # avalia o modelo a cada 10 iterações\n",
    "    if iteration % 10 == 0:\n",
    "        [test_acc, s] = sess.run([test_accuracy, summ], \n",
    "                                 feed_dict={x: mnist.test.images[:n_samples], \n",
    "                                            y: mnist.test.labels[:n_samples],\n",
    "                                            keep_prob: 1.0})\n",
    "        print('Iteration {}, loss = {}.'.format(iteration, iter_loss))\n",
    "        print('Test Accuracy: {0}'.format(test_acc))\n",
    "        writer.add_summary(s, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
